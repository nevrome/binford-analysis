---
output: 
  pdf_document:
    pandoc_args: [
      "-V", "classoption=twocolumn"
    ]
    toc: yes 
    fig_caption: yes
    latex_engine: xelatex
bibliography: bibliography.bib
mainfont: "Arial"
csl: deutsches-archaologisches-institut.csl
---

```{r load libraries, echo=FALSE}
library(magrittr)
library(ggplot2)
# only magrittr and ggplot should be loaded here - everything else should be explicitly mentioned via package::function 
```

# Modelle zur Beschreibung der Ausbreitungsarealgröße von Jäger- und Sammlergruppen

## Problemstellung

Im 5. Kapitel "Designing Frames of Reference and Exploring Projections" beschreibt Binford unter anderem eine Methode, Vorhersagen zu Attributen von Jäger- und Sammlergruppen in globalem Maßstab auf Grundlage von ethnographischen und naturräumlichen Daten treffen und über Projektion auf Karten visualisieren zu können. Im Abschnitt "Projecting Hunter-Gatherer Populations to the Entire Earth" gibt es wiederrum einen Unterabschnitt "Using Relational Projections as Frames of Reference", der das Vorgehen anhand eines Beispiels illustriert. Binford schreibt: 

> If I can develop continously scaled equations that summarize the relationship between the properties of hunter-gatherer systems and suites of environmental variables, it is likely that these equations could be used to project estimates for habitats from which there are few, if any, actual cases of hunter-gatherers documented in the resent past. But since such equations summarize interactive ecological relationships that are not confined to particular time periods, they may furnish strong clues about hunter-gatherer organizational variability that will provide a strong platform for subsequent theory building.  
> 
> -- [@binford_constructing_2001, 154.]

Das Beispiel konzentiert sich auf die Variable AREA -- die Größe des Areals, das von einer Jäger- und Sammlergruppe relativ exklusiv genutzt wird gemessen in Vielfachen von 100km². Mittels multipler Regression auf Grundlage des Gruppendatensatzes kommt Binford zu folgender Gleichung \ref{eq:area_multi} (bzw. umgeformt Gleichung \ref{eq:area_multi_log}), die die abhängige Variable AREA in Relation zu mehreren unabhängigen Variablen (siehe Tabelle \ref{tab:variable_description_1}) beschreibt:

\begin{equation} \label{eq:area_multi}
\begin{aligned}
\mathit{AREA} = \\
    & 10 \mathbin{\char`\^} [3.421431 + \\ 
    & (0.004732 * \mathit{HUNTING}) + \\
    & (-0.387229 * \mathit{LBIO5}) + \\
    & (0.186574 * \mathit{LCOKLM}) + \\
    & (-0.110286 * \mathit{LRUNOFF}) + \\
    & (0.175157 * \mathit{WATRGRC}) + \\
    & (-0.164604 * \mathit{MEDSTAB}) + \\
    & (-0.743144 * \mathit{PERWLTG}) + \\
    & (0.004706 * \mathit{RLOW}) + \\
    & (-0.080339 * \mathit{RUNGRC}) + \\
    & (0.024755 * \mathit{SDTEMP})]
\end{aligned}
\end{equation}

```{r table of variables in binfords model}
# create table data
tibble::tribble(
  ~colA,  ~colB, ~Einheit,
  "AREA", "Größe des Areals, das von einer Jäger- und Sammlergruppe relativ exklusiv genutzt wird", "100km²",
  "LAREA", "siehe AREA", "log10(100km²)",
  "HUNTING", "Ernährungsanteil tierischer, terrestrischer Ressourcen", "%", 
  "LBIO5", "Primäre (pflanzliche) Biomasse", "log(kg/m^2)",
  "LCOKLM", "Distanz zur nächstgelegenen, marinen Küste", "log10(km)", 
  "LRUNOFF", "Wasser, das durch Abfluss für die Nutzung durch Pflanzen verloren geht, ", "log(mm)", 
  "WATRGRC", "Anzahl der Monate im Wachstumszeitraum, in denen Wasser im Boden gespeichert bleibt", "Anzahl", 
  "PERWLTG", "Anteil des Wachstumszeitraum in der die Wasserverfügbarkeit unter dem pflanzlichen Welkepunkt liegt", "%", 
  "RLOW", "Niederschlagsmenge im trockensten Monat des Jahres", "Millimeter", 
  "RUNGRC", "Anzahl der Monate im Wachstumszeitraum in denen der RUNOFF-Wert > 0", "Anzahl",
  "SDTEMP", "Standardabweichung der mittleren Monatstemperatur", "keine Einheit"
) %>%
    dplyr::rename(
    " " = "colA",
    "Beschreibung" = "colB"
  ) %>%
  # table setup and settings
  knitr::kable(
    format = "latex",
    caption = "\\label{tab:variable_description_1}Kurzbeschreibung der Variablen in Binfords Ergebnismodell.",
    booktabs = T
  ) %>%
  kableExtra::column_spec(1, bold = TRUE) %>%
  kableExtra::column_spec(2, width = "16em")
```

Binford hat seine Analyse in SPSS (Version 6.1.2) ausgeführt. Ein Skriptprotokoll der Analysesession liegt mir nicht vor. Um die Ergebnis in Form der Modellgleichung zu reproduzieren, werde ich nun also zunächst versuchen, das Vorgehen so gut wie möglich nachzuvollziehen. Dafür steht mir eine hoffentlich gleiche oder zumindest hochgradig ähnliche Version des oben beschriebene Gruppendatensatz zu Verfügung. Ich weiß weiterhin, dass Binford sein Modell mittels der Methode schrittweiser, Multipler Regression ermittelt hat. Unabhängige Variablen, die sich kollinear zu anderen unabhägigen Variablen verhalten, hat er entfernt. Die abschließende Entscheidung über das beste Modell gibt er an unter Beachtung von den Indikatorgrößen $R^2$ und Standardfehler getroffen zu haben. 

## Datensatz

Ein wesentliches Wissendefizit besteht bezüglich der Information, in welcher Reihenfolge und mit welcher Rechtfertigung in den Schritten der Multiplen Regression Variablen jeweils entfernt wurden. Schon die Angabe welche Variablen im Ausgangsdatensatz berücksichtigt wurden ist unscharf. Immerhin: Da Multiple Regression nur auf Variablen der Intervall- oder Verhältnisskala (zusammen auch Kardinalskala oder metrisch skalierte Variablen) anwendbar ist, lässt sich eine erste Eingrenzung vornehmen. Der Metadatensatz LRBkey verfügt hierzu über die Spalte *type*, die zu jeder Variable ein Skalenniveau angibt. Leider wird nur zwischen "categorical" und "ordinal" unterschieden. Dabei werden alle Variablen jenseits der Nominalskala als "ordinal" angesprochen. Das genügt nicht, um automatisiert alle intervall- und verhältnisskalieren Variablen auszuwählen. Aus diesem Grund habe ich selbst die Spalte *type_exp* im Metadatensatz hinzugefügt, und nach meiner Einschätzung auf Grundlage des Wertebereichs und der Beschreibung eine Zuordnung zu einem der vier Skalenniveaus "nominal", "ordinal", "interval" und "ratio" vorgenommen. Tabelle \ref{tab:variable_key_example} illustriert die Unterschiede zwischen der vorhandenen und meiner neu vorgenommenen Zuordnung für ein paar zufällig ausgewählte Variablen. Abbildung \ref{fig:level_of_meas_bar} zeigt, wie sich die Reevaluation durch die in *type_exp* deutlich akzentuiertere Verteilung der Skalenniveaus auswirkt. 

```{r load binford data, cache=TRUE, message=FALSE, warning=FALSE}
# load data
# TODO: setup correct connections when all datasets are where they are supposed to be
key <- readr::read_csv("../data-raw/LRBkey.csv") #%>%
  #dplyr::rename("variable" = "X1")
main <- binford::LRB
```

```{r variable type example table, cache=TRUE}
# create random subset of key table
key[250:258, ] %>%
  # select showvars
  dplyr::select(variable, description, type, type_exp) %>%
  # add decorative ... at the beginning and end
  rbind(
    data.frame(variable = "...", description = "...", type = "...", type_exp= "..."), 
    .,
    data.frame(variable = "...", description = "...", type = "...", type_exp= "...")
  ) %>%
  # table setup and settings
  knitr::kable(
    format = "latex",
    caption = "\\label{tab:variable_key_example}Auszug aus der Metatabelle mit Variablenbeschreibungen und Skalenniveauklassifizierung in den Spalten \\textit{type} und \\textit{type\\_exp}.",
    booktabs = T
  ) %>%
  kableExtra::column_spec(1, bold = TRUE) %>%
  kableExtra::column_spec(2, width = "10em")
```

```{r type classification distribution plot, cache=TRUE, fig.cap="\\label{fig:level_of_meas_bar}Verteilung der Skalenniveauzuordung in den Variablen *type* und *type_exp* des Metatdatensatzes. *type_exp* habe ich hinzugefügt, um Variablen automatisiert nach ihrer Skalenniveauzuordnung auswählen zu können. Die Klassenzuordnung in *type* ist farblich auf *type_exp* abgetragen."}
# prepare factor levels of type_exp column
key$type_exp <- factor(
  key$type_exp, 
  levels =  c("nominal", "ordinal", "interval", "ratio", "unknown")
)

# barplot of count of type_exp
type_exp_bar <- key %>%
  ggplot(aes(x = type_exp, fill = type)) +
  geom_bar() + 
  theme_bw(base_size = 16) +
  scale_fill_manual(values = c("red", "black")) +
  ylab("") +
  guides(fill = FALSE) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))

# prepare factor levels of type column
key$type <- factor(
  key$type,
  levels <- c("categorical", "ordinal")
)

# barplot of count of type
type_bar <- key %>%
  ggplot(aes(x = type, fill = type)) +
  geom_bar() +
  theme_bw(base_size = 16) +
  scale_fill_manual(values = c("red", "black")) +
  ylab("Anzahl der Variablen") +
  guides(fill = FALSE) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))

# combine plots
cowplot::plot_grid(type_bar, type_exp_bar)
```

```{r apply selection, cache=TRUE}
# get interval and ratio variables 
inter_ratio_vars <- key %>%
  dplyr::filter(
    type_exp %in% c("interval", "ratio")
  ) %$%
  variable

# select only them for further analysis
sel1 <- main %>% 
  dplyr::select(dplyr::one_of(inter_ratio_vars))
```

Auf dieser Grundlage ist es jetzt also möglich, einen Ausgangsdatensatz zusammenstellen, der zwar alle `r nrow(sel1)` Gruppen aber nur die `r ncol(sel1)` interval- und ratioskalierten Variablen enthält. Hier fällt allerdings gleich ein erstes Defizit dieses Datensatzes auf: Einige Variablen haben sehr wenige Einträge, d.h. der Wert der entsprechenden Variable wurde nur bei wenigen Gruppen aufgenommen. Abbildung \ref{fig:is_na_bar} enthält ein Histogramm der Fehlstellenanzahl. 

```{r na histogram, warning=FALSE, fig.cap="\\label{fig:is_na_bar}Verteilung der Fehlstellenanzahl in metrisch skalierten Variablen und den zugehörigen Beobachtungen (Gruppen). Die Klassenbreite der Histogramme beträgt 15. Variablen und Gruppen ohne Fehlstellen wurden für die Visualisierung ausgeschlossen. Die horizontale, rote Linie im Variablenhistogramm markiert die Grenze oberhalb der Variablen aus der weiteren Analyse entfernt wurden."}
# get data.frame with number of na per variable
na_pro_var <- sel1 %>% 
  purrr::map(
    ~sum(is.na(.))
  ) %>% 
  as.data.frame() %>% 
  tidyr::gather() %>%
  # remove variables with zero na
  dplyr::filter(
    value != 0
  )

# get data.frame with number of na per observation
na_pro_obs <- sel1 %>% t %>% as.data.frame() %>%
  purrr::map(
    ~sum(is.na(.))
  ) %>% 
  as.data.frame() %>% 
  tidyr::gather() %>%
  # remove variables with zero na
  dplyr::filter(
    value != 0
  )

# define threshold above which variables will be removed below
na_vars_removal_threshold <- 1/3

# plot histogram for variables
na_vars_plot <- na_pro_var %>%
  ggplot(aes(x = value)) +
  geom_histogram(binwidth = 15, fill = "black") +
  geom_vline(aes(xintercept = na_vars_removal_threshold*ncol(sel1)), color = "red", size = 1) + 
  theme_bw(base_size = 16) +
  ylab("Anzahl der Variablen") +
  xlab("Anzahl der Fehlstellen") +
  coord_flip() +
  xlim(-20, 340)

# plot histogramm for observations
na_obs_plot <- na_pro_obs %>%
  ggplot(aes(x = value)) +
  geom_histogram(binwidth = 15, fill = "black") +
  theme_bw(base_size = 16) +
  ylab("Anzahl der Gruppen") +
  xlab("") +
  coord_flip() +
  xlim(-20, 340)

# combine plots
cowplot::plot_grid(na_vars_plot, na_obs_plot)
```

```{r prepare na values to be printed}
# calculate proportions for text
without_na <- ncol(sel1) - nrow(na_pro_var)
without_na_percent <- round(without_na/ncol(sel1)*100)
```

```{r remove na variables}
# remove vars with more na values than 1/3 * total amount of variables
na_vars_part <- na_pro_var %>%
  dplyr::filter(
    value > (na_vars_removal_threshold)*ncol(sel1)
  )

sel2 <- sel1 %>%
  dplyr::select(
    -dplyr::one_of(na_vars_part$key)
  )
```

Immerhin `r without_na` der `r ncol(sel1)` ($\approx$ `r without_na_percent`%) Variablen besitzen allerdings überhaupt keine Lehrstellen. Der Datensatz ist bemerkenswert vollständig. Ich habe mich entschieden, alle `r nrow(na_vars_part)` Variablen, bei denen mehr als `r paste(MASS::fractions(na_vars_removal_threshold))` der Werte fehlen aus der Analyse auszuschließen, um Problemen bei der Regressionsanalyse vorzubeugen. In Abbildung \ref{fig:is_na_bar} ist die Demarkationslinie rot eingetragen. Bei den gruppenbezogenen Beobachtungen ist das Bild insgesamt ausgeglichener: Für alle Gruppen liegt eine große Menge an Werten vor. Hier sind keine Änderungen erforderlich.

In einem letzten Schritt muss nun noch die Variable AREA durch die Variable LAREA ausgetauscht werden. Binford gibt im Buch zwar die Modellergebnisgleichung für AREA an, das errechnete Modell bezieht sich aber auf den Logarithmus zur Basis 10 von AREA (siehe Umformung von Gleichung \ref{eq:area_multi} zu \ref{eq:area_multi_log}). Der Ergebnisdatensatz wird im folgenden als `sel3` bezeichnet. 

\begin{equation} \label{eq:area_multi_log}
\begin{aligned}
\log _{10} \mathit{AREA} = \\
\mathit{LAREA} = \\
    & 3.421431 + \\ 
    & (0.004732 * \mathit{HUNTING}) + \\
    & (-0.387229 * \mathit{LBIO5}) + \\
    & (0.186574 * \mathit{LCOKLM}) + \\
    & (-0.110286 * \mathit{LRUNOFF}) + \\
    & (0.175157 * \mathit{WATRGRC}) + \\
    & (-0.164604 * \mathit{MEDSTAB}) + \\
    & (-0.743144 * \mathit{PERWLTG}) + \\
    & (0.004706 * \mathit{RLOW}) + \\
    & (-0.080339 * \mathit{RUNGRC}) + \\
    & (0.024755 * \mathit{SDTEMP})
\end{aligned}
\end{equation}

```{r}
# replace   
sel3 <- sel2 %>%
  dplyr::rename(
    "larea" = "area"
  ) %>% 
  dplyr::mutate(
    larea = log10(larea)
  )
```

## Multiple Regression

Multiple Lineare Regression ist ein Verfahren der Multivariaten Statistik, das die Erklärung und Vorhersage einer abhängigen Variable durch mehrere unabhängige Variablen erlaubt^[@backhaus_multivariate_2008, 52-53/64-65.]. Die Berechnung der Regressionsparameter funktioniert wie bei der Einfachen Regressionsanalyse durch Reduktion der Fehlerquadrate. In einem ersten Schritt möchte ich das Modell von Binford nachstellen, indem ich seine Auswahl an Eingabevariablen übernehme und die Regression mittels der Funktion `lm()` aus dem R Basispaket stats darauf anwende. 

```{r recreate binford model, echo=TRUE, cache=TRUE}
binford_model <- lm(
  larea ~ hunting + lbio5 + lcoklm + 
         lrunoff + watrgrc + medstab + perwltg +
         rlow + rungrc + sdtemp, 
  data = sel3
)
```

```{r binford model estimate table, cache=TRUE, dependson="recreate binford model"}
var_vals <- binford_model %>%
  broom::tidy() %>%
  dplyr::mutate_if(
    is.numeric,
    dplyr::funs(round(., 3))
  ) %>%
  dplyr::rename(
    " " = "term"
  )

var_vals %>%
  knitr::kable(
    format = "latex",
    caption = "\\label{tab:binford_model_result}Ergebniszusammenfassung des mit Binfords Variablenauswahl reproduzierten Modells für die einzelnen Koeffizienten. Alle Werte sind auf drei Nachkommastellen gerundet \\newline \\textbf{estimate -- Koeffizient:} Koeffizienten(schätzung) des Ergebnismodells (Intercept und Variablenslopes). \\newline \\textbf{std.error -- Standardfehler:} Durchschnittliche Abweichung des Koeffizienten vom tatsächlichen, durchschnittlichen Wert der abhängigen Variable. Bei einer Variable, die gut für die Vorhersage der abhängigen Variable geeignet ist, sollte der Standardfehler in Relation zum Koeffizienten klein sein.\\newline \\textbf{statistic -- t-Wert:} Anzahl der Standardabweichungen, die den Koeffizienten von Null trennt. Der Betrag des Wertes sollte (auch in Relation zum Standardfehler) groß sein um die Nullhypothese 'keine Relation der Variablen' verwerfen zu können.\\newline \\textbf{p.value -- p-Wert:} p-Wert der t-Statistik. Wahrscheinlichkeit, dass eine Beobachtung auftritt, die gleich oder größer als der t-Wert ist. Ein kleiner p-Wert zeigt an, dass die Wahrscheinlichkeit einer zufälligen Enstehung dieses Modellergebnisses gering ist. Die Relation zwischen abhängiger und unabhängiger Variable ist damit signifikant.\\protect\\footnotemark{}",
    booktabs = T
  ) %>%
  kableExtra::column_spec(1, bold = TRUE)
```

\footnotetext{Zum Verständnis der einzelnen Prüfgrößen:
  \url{https://feliperego.github.io/blog/2015/10/23/Interpreting-Model-Output-In-R}
  {[}23.8.2017{]}}

```{r binford model estimate table 2, cache=TRUE, dependson="recreate binford model"}
mod_vals <- binford_model %>%
  broom::glance() %>%
  tidyr::gather(var, value) %>% 
  dplyr::mutate(
    var2 = c(var[7:11], rep(NA, 6)),
    value2 = c(value[7:11], rep(NA, 6))
  ) %>%
  # df entfällt so
  magrittr::extract(1:5,) %>%
  dplyr::mutate_if(
    is.numeric,
    dplyr::funs(round(., 3))
  ) %>% dplyr::mutate_if(
    is.numeric,
    as.character
  ) %>%
  dplyr::rename(
    " " = "var",
    " " = "var2",
    "value" = "value2"
  )

mod_vals[is.na(mod_vals)] <- ""

mod_vals %>%
  knitr::kable(
    format = "latex",
    caption = "\\label{tab:binford_model_result_2}Ergebniszusammenfassung des mit Binfords Variablenauswahl reproduzierten Modells für das Gesamtmodell. Alle Werte sind auf drei Nachkommastellen gerundet. \\newline \\textbf{r.squared -- $R^2$ -- Bestimmtheitsmaß:} $R^2$ ist ein Maß für die Güte der Modelleinpassung. Es gibt den Anteil der Varianz der abhängigen Variablen wieder, der durch das lineare Modell erklärt wird. Der Wert liegt zwischen 0 (kein linearer Zusammenhang) und 1 (perfekter linearer Zusammenhang). Ein hoher Wert ist ein Indikator für ein gutes Modell.\\newline \\textbf{adj.r.squared -- korrigiertes Bestimmtheitsmaß:} $R^2$ korrigiert unter Beachtung der Anzahl unabhängigen Variablen. $R^2$ wird bei zunehmender Anzahl an Variablen größer und muss entsprechend bei Multipler Regression normiert werden. \\newline \\textbf{sigma -- Residual Standard Error:} Durchschnittliche Abweichung der Modellvorhersage für die unabhängige Variable von den tatsächlich gemessenen Werten. Bei einem guten Modell sollte der Wert gering sein. \\newline \\textbf{statistic und p.value} Siehe Tabelle \\ref{tab:binford_model_result}. Hier beziehen sich die Werte auf das Gesamtmodell. \\newline \\textbf{logLik -- Log\\-Likelihood, AIC -- Akaike Information Criterion und BIC -- Bayesian Information Criterion} Maße für die Güte der Modelleinpassung. \\newline \\textbf{deviance} Maß für die Distance zweier Modelle. Hier als Maß für die Güte der Modelleinpassung indem das Ergebnismodell mit dem Null\\-Modell (Modell nur unter Beachtung des Intercept) verglichen wird. \\newline \\textbf{df.residual -- Anzahl der Freiheitsgrade} Berechnet sich aus der Anzahl der Beobachtungen abzüglich der Anzahl der schätzbaren Koeffizienten. Insofern handelt es sich um die Anzahl der 'überflüssigen' Messwerte, die zur Berechnung der Modellparameter nicht erforderlich wären.\\protect\\footnotemark{}",
    booktabs = T
  ) %>%
  kableExtra::column_spec(1, bold = TRUE) %>%
  kableExtra::column_spec(3, bold = TRUE)
```

\footnotetext{ebenda}

```{r plot binford model, warning=FALSE, cache=TRUE, dependson="recreate binford model", fig.height=7, fig.cap="\\label{fig:binford_model_plot}Diagnostische Plots für das mit Binfords Variablenauswahl reproduzierte Modell. \\newline \\textbf{Residuals vs Fitted:} Streuung der Residuen in Abhängigkeit von der Modellvorhersage. Kann als Indikator für nicht lineare Trends dienen. \\newline \\textbf{Normal Q-Q:} Sortierte Residuenwerte abgetragen auf die theoretischen Quantile einer Normalverteilung. Zeigt, inwiefern die Residuenverteilung der Normalverteilung entspricht. \\newline \\textbf{Scale-Location:} Vergleiche Residuals vs Fitted. Die Umskalierung erlaubt es, die Homogenität der Residuenvarianz (Homoskedastizität) besser zu beurteilen.  \\newline \\textbf{Residuals vs Leverage:} Standardisierte Residuenwerte abgetragen auf ein Maß zur Einschätzung des Einflusses auf das Modellergebnis. Dient zum Identifizieren von einflussreichen Ausreißern. ^[Zum Verständnis der diagnostischen Plots: http://data.library.virginia.edu/diagnostic-plots [16.8.2017]]"}
opar <- par(mfrow=c(2,2)) 
plot(binford_model)
par(opar) 
```

```{r identify bad observations for binford model}
# visual obersvations at the plots allow identification of outliers:
outies_binford_model <- c(54, 296, 309)
outies_binford_model_names <- main$X[outies_binford_model]
```

Tabelle \ref{tab:binford_model_result} enthälten Koeffizienten und zugehörige Kennwerte des erzeugten Modells. Ein Vergleich der Werte mit jenen in Gleichung \ref{eq:area_multi_log} ergibt, dass die Koeffizienten von den von Binford errechneten abweichen. Ich gehe davon aus, dass der Regressionsalgorithmus in SPSS geringfügig anders implementiert ist als derjenigen in `lm()` oder SPSS die Regression nicht mittels der Kleinste-Quadrate-Methode durchführt. Da die Werte nur geringfügig divergieren und Größenordnung sowie Vorzeichen übereinstimmen, gehe ich von einer nicht relevanten Abweichung aus, die ich hier nicht weiter diskutieren möchte. Tabelle \ref{tab:binford_model_result_2} gibt einige Kennwerte der Modellgüte wieder und Abbildung \ref{fig:binford_model_plot} die vier diagnostischen Standardplots, die die Funktion `plot.lm()` aus stats bereitstellt. Das Modell scheint eine hohe Erklärungspotenz zu besitzen, die abhängige Variable AREA also gut zu beschreiben. Starke Ausreißer gibt es nicht -- die überwiegende Mehrzahl der Beobachtungen wird durch das Modell gut erklärt. Nur einzelne Beobachtungen zeigen Auffälligkeiten: `r paste0(paste0(outies_binford_model, ": ", outies_binford_model_names), collapse = ", ")`. 

Ich möchte nun versuchen, selbst ein Modell für die Variable AREA zu erstellen. Das Ergebnis der Multiplen Regression ist dabei einerseits abhängig von den Eingabevariablen, andererseits aber auch -- zumindest wenn sie nicht vollständig unkorreliert sind -- von deren Eingabereihenfolge. Da im Fall der vorliegenden Analyse keine theoretischen oder sachlogischen Überlegungen Eingang finden sollen, die die Variablenauswahl determinieren würden, müssten eigentlich alle Permutationen von Auswahl und Reihenfolge betrachtet werden. Bei `r ncol(sel3) - 1` unabhängigen Variablen ist allerdings die Anzahl allein der Permutationen weit größer als praktisch in irgendeiner Form verarbeitbar ($200! \approx 7.887*10^{374}$). Aus diesem Grund muss auf ein Verfahren der Schrittweisen Regressionsanalyse zurückgegriffen werden, das mittels Prüfgrößen selbständig und in verhältnismäßig wenigen Iterationsschritten eine Variablenauswahl trifft^[@backhaus_multivariate_2008, 100-105.].  

Ich habe mich hier für die Implementierung eines solchen Verfahrens in der Funktion `stepAIC()` des R Pakets MASS^[@venables_modern_2002, 172-177.] entschieden. `stepAIC()` erreicht die Modellreduktion durch schrittweise Minimierung der Prüfgröße AIC (Akaike Information Criterion -- $\mathit{AIC} = -2 * \mathit{maximierte} \mathit{Log-Likelihood} + 2 * \# Parameter$), die man vereinfacht als Maß für die Passgenauigkeit eines statistischen Modells verstehen kann. `stepAIC()` benötigt dafür ein berechnetes Eingangsmodell, das nach Möglichkeit nah am besten Ergebnismodell liegen sollte, sowie Modelldefinitionen jeweils eines maximal und minimal komplexen Ergebnismodells. Da das Ausgangsmodell mit `r nrow(sel3)` Beobachtungen und `r ncol(sel3)` Variablen in diesem Kontext als komplex gelten darf, möchte ich mich zunächst an folgende Empfehlung der Autoren halten, und dem Algorithmus stattdessen nur dieses Initialmodell zur Verfügung stellen.

> If a large model is selected as the starting point, the scope and scale arguments have generally reasonable defaults, but for a small model where the process is probably to be one of adding terms, they will usually need both to be supplied. 
>  
> -- [@venables_modern_2002, 175.]

Zunächst erfolgt die Berechnung des Ausgangsmodells:

```{r create initial model, echo = TRUE, cache=TRUE} 
initial_model <- lm(larea ~ ., data = sel3)
```

```{r plot initial model, warning=FALSE, cache=TRUE, dependson="create initial model", fig.height=7, fig.cap="\\label{fig:initial_model_plot}Diagnostische Plots für das Ausgangsmodell mit allen Variablen."}
opar <- par(mfrow=c(2,2)) 
plot(initial_model)
par(opar) 
```

```{r initial model estimate table 2, cache=TRUE, dependson="create initial model"}
init_mod_vals <- initial_model %>%
  broom::glance() %>%
  tidyr::gather(var, value) %>% 
  dplyr::mutate(
    var2 = c(var[7:11], rep(NA, 6)),
    value2 = c(value[7:11], rep(NA, 6))
  ) %>%
  magrittr::extract(1:5,) %>%
  dplyr::mutate_if(
    is.numeric,
    dplyr::funs(round(., 3))
  ) %>% dplyr::mutate_if(
    is.numeric,
    as.character
  ) %>%
  dplyr::rename(
    " " = "var",
    " " = "var2",
    "value" = "value2"
  )

init_mod_vals[is.na(init_mod_vals)] <- ""

init_mod_vals %>%
  knitr::kable(
    format = "latex",
    caption = "\\label{tab:initial_model_result_2}Ergebniszusammenfassung des initialen Modells. Alle Werte sind auf drei Nachkommastellen gerundet.",
    booktabs = T
  ) %>%
  kableExtra::column_spec(1, bold = TRUE) %>%
  kableExtra::column_spec(3, bold = TRUE)
```

Abbildung \ref{fig:initial_model_plot} und Tabelle \ref{tab:initial_model_result_2} zeigen, dass dieses Modell auf Grundlage aller Variablen herausragende Vorhersagefähigkeiten für die Variable AREA besitzt. Gleichermaßen entbehrt es jedoch jeder fachwissenschaftlichen Aussage, da sich eine Gesamtheit von `r ncol(sel3)` semantisch höchst unterschiedlichen Variablen jeder integrativen Interpretation entzieht. Das Modell ist nicht geeignet, ein besseres Verständnis der zugrundeliegenden naturräumlichen, kulturellen und sozioökonomischen Zusammenhänge zu generieren. Erst die Vereinfachung des Modells wird die Ableitung klarer, prüfbarer Hypothesen ermöglichen.

Entsprechend nun also ein erster Durchlauf der automatischen, schrittweisen Modellreduktion: 

```{r stepwise multiple regression, cache=TRUE, dependson="create initial model", message=FALSE, echo=TRUE}
model1 <- MASS::stepAIC(
  initial_model, 
  # don't show intermediate steps
  trace = FALSE
)
```

```{r plot model1, warning=FALSE, cache=TRUE, dependson="stepwise multiple regression", fig.height=7, fig.cap="\\label{fig:model1_plot}Diagnostische Plots für das Modell nach dem ersten Durchlauf von `stepAIC()`."}
opar <- par(mfrow=c(2,2)) 
plot(model1)
par(opar) 
```

```{r anova table of stepAIC, cache=TRUE, dependson="stepwise multiple regression"}
model1$anova %>% as.data.frame() %>% dplyr::rename("Dev" = "Deviance") %>% knitr::kable(
    format = "latex",
    caption = "\\label{tab:model1_anova}ANOVA Komponente des Ergebnismodelldatentyps von `stepAIC()`.  Zeigt die schrittweise Entfernung von Variablen zur Reduktion der Modellkomplexität und zugehörige, diagnostische Prüfgrößen. \\newline \\textbf{Step:} Variable, die in diesem Schritt entfernt oder hinzugefügt wurde \\newline \\textbf{Df -- degrees of freedom:} Anzahl der Freiheitsgrade ('Anzahl der Werte in der abschließenden Berechnung einer Statistik, die frei variieren können') \\newline \\textbf{Dev -- Deviance:} Unterschied in der Summe der Fehlerquadrate gegenüber dem vorangegangenen Schritt \\newline \\textbf{Resid. Df -- residual degrees of freedom:} Gesamtanzahl der Freiheitsgrade minus Freiheitsgrade des Modells \\newline \\textbf{Resid. Dev -- residual deviance:}  \\newline \\textbf{AIC -- Akaike information criterion:} siehe Text",
    booktabs = T
  ) %>%
  kableExtra::column_spec(1, bold = TRUE) %>%
  kableExtra::kable_styling(font_size = 8)
```

In Tabelle \ref{tab:model1_anova} werden die Reduktionsschritte zeilenweise dokumentiert. `r nrow(model1$anova)` Variablen wurden von `stepAIC()` entfernt, dann allerdings kam der Prozess in diesem Durchlauf zum halten. Der Vergleich des *Residuals vs Leverage* Plots in Abbildung \ref{fig:initial_model_plot} und Abbildung \ref{fig:model1_plot} legt nahe, dass sich die durchschnittliche Wirkung individueller Beobachtungen auf das Gesamtergebnis verringert hat. Anzunehmen ist, dass Variablen mit großer Variablität entfernt wurden. Der Vergleich mit Abbildung \ref{fig:binford_model_plot} lässt die Vermutung zu, dass sich dieser Trend bei weiterer Reduktion des Modells fortsetzen wird. `r ncol(sel3) - nrow(model1$anova)` Variablen sind tatsächlich angesichts der deskriptiven Einfachheit des Binford-Modells noch kein befriedigendes Vereinfachungsergebnis. Die Minimierung des AIC-Werts ist scheinbar kein starkes Optimierungskriterium:

> This suggests, correctly, that selecting terms on the basis of AIC can be somewhat permissive in its choice of terms, being roughly equivalent to choosing an F-cutoff of 2.  
>  
> -- [@venables_modern_2002, 176.]

Wir können nun fortfahren, indem wir entweder das k-Attribut in `stepAIC()` (*the multiple of the number of degrees of freedom used for the penalty*) erhöhen und den Prozess erneut starten, oder mittels F-Statistik schrittweise jene Variablen entfernen, die keinen signifikanten Einfluss auf das Ergebnismodell nehmen. Um diese zu identifizieren, steht in MASS die Funktion `dropterm()` bereit.  

<!-- https://www.r-bloggers.com/manual-variable-selection-using-the-dropterm-function/ --> 

```{r dropterm example code, eval=FALSE, echo=TRUE}
MASS::dropterm(model1, test = "F")
```

Tabelle \ref{tab:dropterm_example} gibt Einblick... <!-- TODO -->

```{r dropterm example table, cache=TRUE, cache=TRUE, dependson="stepwise multiple regression"}
MASS::dropterm(model1, test = "F") %>%
  as.data.frame() %>%
  magrittr::extract(1:10, ) %>%
  tibble::rownames_to_column() %>%
  dplyr::select(
    -AIC
  ) %>%
  dplyr::mutate_at(
    c("Sum of Sq", "RSS", "F Value"),
    dplyr::funs(round(., 2))
  ) %>%  
  dplyr::mutate_at(
    c("Pr(F)"),
    dplyr::funs(round(., 4))
  ) %>%
  dplyr::mutate_all(
    dplyr::funs(as.character(.))
  ) %>%
  # add decorative ... at the beginning and end
  rbind(
    ., 
    data.frame(
      rowname = "...", Df = "...", `Sum of Sq` = "...", RSS = "...",
      `F Value` = "...", `Pr(F)` = "...", check.names = F
    )
  ) %>%
  knitr::kable(
    format = "latex",
    caption = "\\label{tab:dropterm_example}dropterm Tabelle: Maße der Modellgüte für verschiedene Variablen \\newline \\textbf{Df - degrees of freedom:} siehe oben \\newline \\textbf{Sum of Sq -- sum of squared deviations:} Abweichung der individuellen Werte vom Mittelwert aller Werte \\newline \\textbf{RSS -- residual sum of squares:} Abweichung der Vorhersagen für die abhängige Variable von ihren tatsächlichen Werten \\newline \\textbf{AIC -- Akaike information criterion:} siehe Text \\newline \\textbf{F Value:} Einganswert des F-Tests \\newline \\textbf{Pr(F) -- probability of F-Value:} Maß für die Wahrscheinlichkeit des F-Werts. Kleine Werte sind ein Indikator für eine wichtige Variable",
    booktabs = T
  ) %>%
  kableExtra::column_spec(1, bold = TRUE)
```

Ich möchte das Vorgehen, mit `dropterm()` schrittweise Variablen zu entfernen automatisieren und dann so oft wiederholt zur Anwendung bringen, bis die Anzahl der Variablen im Ergebnismodell der in Binfords Modell entspricht. Dafür habe ich einen simplen Algorithmus formuliert, der in einer Schleife die `dropterm()`-Funktion ausführt, die Variable mit dem größten p-Wert identifiziert und diese dann dann für den nächsten Schleifendurchlauf aus dem Modell entfernt. 

```{r dropterm loop, echo=TRUE, cache=TRUE, dependson="stepwise multiple regression"}
# dublicate model object 
model2 <- model1

# determine number of vars to drop
to_drop <- (ncol(sel3) - nrow(model1$anova) - 10)

# drop loop
for (i in 1:to_drop) {
  # determine variable with highest 
  # p-value of the F-Test
  victimvar <- MASS::dropterm(
      model2, test = "F"
    ) %>% 
    tibble::as.tibble() %>%
    tibble::rownames_to_column() %>%
    dplyr::top_n(
     1, `Pr(F)`
    ) 
  
  # remove this variable from the model
  model2 <- update(
    model2, 
    as.formula(paste(
      ". ~ . - ", victimvar$rowname
    ))
  ) 
}
```

```{r plot model2, warning=FALSE, cache=TRUE, dependson="dropterm loop", fig.height=7, fig.cap="\\label{fig:model2_plot}Diagnostische Plots für das Modell nach ...."}
opar <- par(mfrow=c(2,2)) 
plot(model2)
par(opar) 
```

```{r, cache=TRUE, dependson="dropterm loop"}
model2 %>%
  broom::tidy() %>%
  dplyr::mutate_if(
    is.numeric,
    dplyr::funs(round(., 3))
  ) %>%
  knitr::kable(
    format = "latex",
    caption = "\\label{tab:model2_result}Modellergebnis.",
    booktabs = T
  ) %>%
  kableExtra::column_spec(1, bold = TRUE)
```

Haha...

```{r final model, cache=TRUE}
# get variable descriptions
# hu <- key %>%
#   dplyr::filter(
#     variable %in% colnames(sel3)
#   ) %>%
#   dplyr::select(
#     variable, description
#   )

# manually identify variables, that are directly linked to AREA
bad_vars <- c("density", "packinx", "prindx", "lden", "lpackinx")

# remove those variables
sel5 <- sel3 %>%
  dplyr::select(
    -dplyr::one_of(bad_vars)
  )

# create initial model with new variable selection
initial_model2 <- lm(larea ~ ., data = sel5)

# reduce model with stepAIC()
model3 <- MASS::stepAIC(
  initial_model2, 
  trace = FALSE
)

# dublicate model object 
model4 <- model3

# determine number of vars to drop
to_drop <- (ncol(sel5) - nrow(model3$anova) - 10)

# drop loop
for (i in 1:to_drop) {
  # determine variable with highest 
  # p-value of the F-Test
  victimvar <- MASS::dropterm(
      model4, test = "F"
    ) %>% 
    tibble::as.tibble() %>%
    tibble::rownames_to_column() %>%
    dplyr::top_n(
     1, `Pr(F)`
    ) 
  
  # remove this variable from the model
  model4 <- update(
    model4, 
    as.formula(paste(
      ". ~ . - ", victimvar$rowname
    ))
  ) 
}
```

```{r plot model4, warning=FALSE, cache=TRUE, dependson="dropterm loop", fig.height=7, fig.cap="\\label{fig:model2_plot}Diagnostische Plots für das finale Modell ...."}
opar <- par(mfrow=c(2,2)) 
plot(model4)
par(opar) 
```

```{r final model estimate table, cache=TRUE, dependson="dropterm loop"}
model4 %>%
  broom::tidy() %>%
  dplyr::mutate_if(
    is.numeric,
    dplyr::funs(round(., 3))
  ) %>%
  knitr::kable(
    format = "latex",
    caption = "\\label{tab:model4_result}Modellergebnis.",
    booktabs = T
  ) %>%
  kableExtra::column_spec(1, bold = TRUE)
```

```{r final model estimate table 2, cache=TRUE, dependson="dropterm loop"}
fin_mod_vals <- model4 %>%
  broom::glance() %>%
  tidyr::gather(var, value) %>% 
  dplyr::mutate(
    var2 = c(var[7:11], rep(NA, 6)),
    value2 = c(value[7:11], rep(NA, 6))
  ) %>%
  magrittr::extract(1:5,) %>%
  dplyr::mutate_if(
    is.numeric,
    dplyr::funs(round(., 3))
  ) %>% dplyr::mutate_if(
    is.numeric,
    as.character
  ) %>%
  dplyr::rename(
    " " = "var",
    " " = "var2",
    "value" = "value2"
  )

fin_mod_vals[is.na(fin_mod_vals)] <- ""

fin_mod_vals %>%
  knitr::kable(
    format = "latex",
    caption = "\\label{tab:binford_model_result_2}Ergebniszusammenfassung des finalen Modells. Alle Werte sind auf drei Nachkommastellen gerundet.",
    booktabs = T
  ) %>%
  kableExtra::column_spec(1, bold = TRUE) %>%
  kableExtra::column_spec(3, bold = TRUE)
```

## Vergleich der Ergebnismodelle

Vergleichen wir nun also kurz
