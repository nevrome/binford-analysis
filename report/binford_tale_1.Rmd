---
output: 
  pdf_document:
    pandoc_args: [
      "-V", "classoption=twocolumn"
    ]
    toc: yes 
    fig_caption: yes
    latex_engine: xelatex
bibliography: bibliography.bib
mainfont: "Arial"
csl: deutsches-archaologisches-institut.csl
---

```{r load libraries, echo=FALSE}
library(magrittr)
library(ggplot2)
# only magrittr and ggplot should be loaded here - everything else should be explicitly mentioned via package::function 
```

# Modelle zur Beschreibung der Ausbreitungsarealgröße von Jäger- und Sammlergruppen

## Problemstellung

Im 5. Kapitel "Designing Frames of Reference and Exploring Projections" beschreibt Binford unter anderem eine Methode, Vorhersagen zu Attributen von Jäger- und Sammlergruppen in globalem Maßstab auf Grundlage von ethnographischen und naturräumlichen Daten treffen und über Projektion auf Karten visualisieren zu können. Im Abschnitt "Projecting Hunter-Gatherer Populations to the Entire Earth" gibt es wiederrum einen Unterabschnitt "Using Relational Projections as Frames of Reference", der das Vorgehen anhand eines Beispiels illustriert. Binford schreibt: 

> If I can develop continously scaled equations that summarize the relationship between the properties of hunter-gatherer systems and suites of environmental variables, it is likely that these equations could be used to project estimates for habitats from which there are few, if any, actual cases of hunter-gatherers documented in the resent past. But since such equations summarize interactive ecological relationships that are not confined to particular time periods, they may furnish strong clues about hunter-gatherer organizational variability that will provide a strong platform for subsequent theory building.  
> 
> -- [@binford_constructing_2001, 154.]

Das Beispiel konzentiert sich auf die Variable AREA -- die Größe des Areals, das von einer Jäger- und Sammlergruppe relativ exklusiv genutzt wird gemessen in Vielfachen von 100km². Mittels multipler Regression auf Grundlage des Gruppendatensatzes kommt Binford zu folgender Gleichung \ref{eq:area_multi}, die die abhängige Variable AREA in Relation zu mehreren unabhängigen Variablen (siehe Tabelle \ref{tab:variable_description_1}) beschreibt:

\begin{equation} \label{eq:area_multi}
\begin{aligned}
\mathit{AREA} = & 10 \mathbin{\char`\^} [3.421431 + \\ 
                & (0.004732 * \mathit{HUNTING}) + \\
                & (-0.387229 * \mathit{LBIO5}) + \\
                & (0.186574 * \mathit{LCOKLM}) + \\
                & (-0.110286 * \mathit{LRUNOFF}) + \\
                & (0.175157 * \mathit{WATRGRC}) + \\
                & (-0.743144 * \mathit{PERWLTG}) + \\
                & (0.004706 * \mathit{RLOW}) + \\
                & (-0.080339 * \mathit{RUNGRC}) + \\
                & (0.024755 * \mathit{SDTEMP})]
\end{aligned}
\end{equation}

```{r table of variables in binfords model}
# create table data
tibble::tribble(
  ~colA,  ~colB, ~Einheit,
  "AREA", "Größe des Areals, das von einer Jäger- und Sammlergruppe relativ exklusiv genutzt wird", "100km²",
  "HUNTING", "Ernährungsanteil tierischer, terrestrischer Ressourcen", "%", 
  "LBIO5", "Primäre (pflanzliche) Biomasse", "log(kg/m^2)",
  "LCOKLM", "Distanz zur nächstgelegenen, marinen Küste", "log10(km)", 
  "LRUNOFF", "Wasser, das durch Abfluss für die Nutzung durch Pflanzen verloren geht, ", "log(mm)", 
  "WATRGRC", "Anzahl der Monate im Wachstumszeitraum, in denen Wasser im Boden gespeichert bleibt", "Anzahl", 
  "PERWLTG", "Anteil des Wachstumszeitraum in der die Wasserverfügbarkeit unter dem pflanzlichen Welkepunkt liegt", "%", 
  "RLOW", "Niederschlagsmenge im trockensten Monat des Jahres", "Millimeter", 
  "RUNGRC", "Anzahl der Monate im Wachstumszeitraum in denen der RUNOFF-Wert > 0", "Anzahl",
  "SDTEMP", "Standardabweichung der mittleren Monatstemperatur", "keine Einheit"
) %>%
  # table setup and settings
  knitr::kable(
    format = "latex",
    caption = "\\label{tab:variable_description_1}Kurzbeschreibung der Variablen in Binfords Ergebnismodell.",
    booktabs = T
  ) %>%
  kableExtra::column_spec(1, bold = TRUE) %>%
  kableExtra::column_spec(2, width = "13em")
```

Binford hat seine Analyse in SPSS (Version 6.1.2) ausgeführt. Ein Skriptprotokoll der Analysesession liegt mir nicht vor. Um die Ergebnis in Form der Modellgleichung zu reproduzieren, werde ich nun also zunächst versuchen, das Vorgehen so gut wie möglich nachzuvollziehen. Dafür steht mir eine hoffentlich gleiche oder zumindest hochgradig ähnliche Version des oben beschriebene Gruppendatensatz zu Verfügung. Ich weiß weiterhin, dass Binford sein Modell mittels der Methode schrittweiser, Multipler Regression ermittelt hat. Unabhängige Variablen, die sich kollinear zu anderen unabhägigen Variablen verhalten, hat er entfernt. Die abschließende Entscheidung über das beste Modell hat er unter Beachtung von den Indikatorgrößen $R^2$ und Standardfehler getroffen. 

## Datensatz

Ein wesentliches Wissendefizit besteht bezüglich der Information, in welcher Reihenfolge und mit welcher Rechtfertigung in den Schritten der Multiplen Regression Variablen entfernt wurden. Schon die Angabe welche Variablen im Ausgangsdatensatz berücksichtigt wurden ist unscharf. Immerhin: Da Multiple Regression nur auf Variablen der Intervall- oder Verhältnisskala (zusammen auch Kardinalskala oder metrisch skalierte Variablen) anwendbar ist, lässt sich eine erste Eingrenzung vornehmen. Der Metadatensatz LRBkey verfügt hierzu über die Spalte *type*, die zu jeder Variable ein Skalenniveau angibt. Leider wird nur zwischen "categorical" und "ordinal" unterschieden. Dabei werden alle Variablen jenseits der Nominalskala als "ordinal" angesprochen. Das genügt nicht, um automatisiert alle intervall- und verhältnisskalieren Variablen auszuwählen. Aus diesem Grund habe ich selbst die Spalte *type_exp* im Metadatensatz hinzugefügt, und nach meiner Einschätzung auf Grundlage des Wertebereichs und der Beschreibung eine Zuordnung zu einem der vier Skalenniveaus "nominal", "ordinal", "interval" und "ratio" vorgenommen. Tabelle \ref{tab:variable_key_example} illustriert die Unterschiede zwischen der vorhandenen und meiner neu vorgenommenen Zuordnung für ein paar zufällig ausgewählte Variablen. Abbildung \ref{fig:level_of_meas_bar} zeigt, wie sich die Reevaluation durch die in *type_exp* deutlich akzentuiertere Verteilung der Skalenniveaus auswirkt. 

```{r load binford data, cache=TRUE, message=FALSE, warning=FALSE}
# load data
# TODO: setup correct connections when all datasets are where they are supposed to be
key <- readr::read_csv("../data-raw/LRBkey.csv") #%>%
  #dplyr::rename("variable" = "X1")
main <- binford::LRB
```

```{r variable type example table, cache=TRUE}
# create random subset of key table
key[250:258, ] %>%
  # select showvars
  dplyr::select(variable, description, type, type_exp) %>%
  # add decorative ... at the beginning and end
  rbind(
    data.frame(variable = "...", description = "...", type = "...", type_exp= "..."), 
    .,
    data.frame(variable = "...", description = "...", type = "...", type_exp= "...")
  ) %>%
  # table setup and settings
  knitr::kable(
    format = "latex",
    caption = "\\label{tab:variable_key_example}Auszug aus der Metatabelle mit Variablenbeschreibungen und Skalenniveauklassifizierung in den Spalten \\textit{type} und \\textit{type\\_exp}.",
    booktabs = T
  ) %>%
  kableExtra::column_spec(1, bold = TRUE) %>%
  kableExtra::column_spec(2, width = "10em")
```

```{r type classification distribution plot, cache=TRUE, fig.cap="\\label{fig:level_of_meas_bar}Verteilung der Skalenniveauzuordung in den Variablen *type* und *type_exp* des Metatdatensatzes. *type_exp* habe ich hinzugefügt, um Variablen automatisiert nach ihrer Skalenniveauzuordnung auswählen zu können. Die Klassenzuordnung in *type* ist farblich auf *type_exp* abgetragen."}
# prepare factor levels of type_exp column
key$type_exp <- factor(
  key$type_exp, 
  levels =  c("nominal", "ordinal", "interval", "ratio", "unknown")
)

# barplot of count of type_exp
type_exp_bar <- key %>%
  ggplot(aes(x = type_exp, fill = type)) +
  geom_bar() + 
  theme_bw(base_size = 16) +
  scale_fill_manual(values = c("red", "black")) +
  ylab("") +
  guides(fill = FALSE) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))

# prepare factor levels of type column
key$type <- factor(
  key$type,
  levels <- c("categorical", "ordinal")
)

# barplot of count of type
type_bar <- key %>%
  ggplot(aes(x = type, fill = type)) +
  geom_bar() +
  theme_bw(base_size = 16) +
  scale_fill_manual(values = c("red", "black")) +
  ylab("Anzahl der Variablen") +
  guides(fill = FALSE) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))

# combine plots
cowplot::plot_grid(type_bar, type_exp_bar)
```

```{r apply selection, cache=TRUE}
# get interval and ratio variables 
inter_ratio_vars <- key %>%
  dplyr::filter(
    type_exp %in% c("interval", "ratio")
  ) %$%
  variable

# select only them for further analysis
sel1 <- main %>% 
  dplyr::select(dplyr::one_of(inter_ratio_vars))
```

Auf dieser Grundlage ist es jetzt also möglich, einen Ausgangsdatensatz zusammenstellen, der zwar alle `r nrow(sel1)` Gruppen aber nur die `r ncol(sel1)` interval- und ratioskalierten Variablen enthält. Hier fällt allerdings gleich ein erstes Defizit dieses Datensatzes auf: Einige Variablen haben sehr wenige Einträge, d.h. der Wert der entsprechenden Variable wurde nur bei wenigen Gruppen aufgenommen. Abbildung \ref{fig:is_na_bar} enthält ein Histogramm der Fehlstellenanzahl. 

```{r na histogram, warning=FALSE, fig.cap="\\label{fig:is_na_bar}Verteilung der Fehlstellenanzahl in metrisch skalierten Variablen und den zugehörigen Beobachtungen (Gruppen). Die Klassenbreite der Histogramme beträgt 15. Variablen und Gruppen ohne Fehlstellen wurden für die Visualisierung ausgeschlossen. Die horizontale, rote Linie im Variablenhistogramm markiert die Grenze oberhalb der Variablen aus der weiteren Analyse entfernt wurden."}
# get data.frame with number of na per variable
na_pro_var <- sel1 %>% 
  purrr::map(
    ~sum(is.na(.))
  ) %>% 
  as.data.frame() %>% 
  tidyr::gather() %>%
  # remove variables with zero na
  dplyr::filter(
    value != 0
  )

# get data.frame with number of na per observation
na_pro_obs <- sel1 %>% t %>% as.data.frame() %>%
  purrr::map(
    ~sum(is.na(.))
  ) %>% 
  as.data.frame() %>% 
  tidyr::gather() %>%
  # remove variables with zero na
  dplyr::filter(
    value != 0
  )

# define threshold above which variables will be removed below
na_vars_removal_threshold <- 1/3

# plot histogram for variables
na_vars_plot <- na_pro_var %>%
  ggplot(aes(x = value)) +
  geom_histogram(binwidth = 15, fill = "black") +
  geom_vline(aes(xintercept = na_vars_removal_threshold*ncol(sel1)), color = "red", size = 1) + 
  theme_bw(base_size = 16) +
  ylab("Anzahl der Variablen") +
  xlab("Anzahl der Fehlstellen") +
  coord_flip() +
  xlim(-20, 340)

# plot histogramm for observations
na_obs_plot <- na_pro_obs %>%
  ggplot(aes(x = value)) +
  geom_histogram(binwidth = 15, fill = "black") +
  theme_bw(base_size = 16) +
  ylab("Anzahl der Gruppen") +
  xlab("") +
  coord_flip() +
  xlim(-20, 340)

# combine plots
cowplot::plot_grid(na_vars_plot, na_obs_plot)
```

```{r prepare na values to be printed}
# calculate proportions for text
without_na <- ncol(sel1) - nrow(na_pro_var)
without_na_percent <- round(without_na/ncol(sel1)*100)
```

```{r remove na variables}
# remove vars with more na values than 1/3 * total amount of variables
na_vars_part <- na_pro_var %>%
  dplyr::filter(
    value > (na_vars_removal_threshold)*ncol(sel1)
  )

sel2 <- sel1 %>%
  dplyr::select(
    -dplyr::one_of(na_vars_part$key)
  )
```

Immerhin `r without_na` der `r ncol(sel1)` ($\approx$ `r without_na_percent`%) Variablen besitzen allerdings überhaupt keine Lehrstellen. Der Datensatz ist bemerkenswert vollständig. Ich habe mich entschieden, alle `r nrow(na_vars_part)` Variablen, bei denen mehr als `r paste(MASS::fractions(na_vars_removal_threshold))` der Werte fehlen aus der Analyse auszuschließen, um Problemen bei der Regressionsanalyse vorzubeugen. In Abbildung \ref{fig:is_na_bar} ist die Demarkationslinie rot eingetragen. Bei den gruppenbezogenen Beobachtungen ist das Bild insgesamt ausgeglichener: Für alle Gruppen liegt eine große Menge an Werten vor. Hier sind keine Änderungen erforderlich.

## Multiple Regression

Multiple Lineare Regression ist ein Verfahren der Multivariaten Statistik, das die Erklärung und Vorhersage einer abhängigen Variable durch mehrere unabhängige Variablen erlaubt^[@backhaus_multivariate_2008, 52-53/64-65.]. Die Berechnung der Regressionsparameter funktioniert wie bei der Einfachen Regressionsanalyse durch Reduktion der Fehlerquadrate. In einem ersten Schritt möchte ich das Modell von Binford nachstellen, indem ich seine Auswahl an Eingabevariablen übernehme und die Regression mittels der Funktion `lm()` aus dem R Basispaket stats darauf anwende. 

```{r recreate binford model, echo=TRUE}
binford_model <- lm(
  area ~ hunting + lbio5 + lcoklm + 
         lrunoff + watrgrc + medstab + perwltg +
         rlow + rungrc + sdtemp, 
  data = main
)
```

```{r}
binford_model %>%
  broom::tidy() %>%
  dplyr::mutate_if(
    is.numeric,
    dplyr::funs(round(., 2))
  ) %>%
  knitr::kable(
    format = "latex",
    caption = "\\label{tab:binford_model_result}Modellergebnis. \\newline \\textbf{term:} \\newline \\textbf{estimate:} \\newline \\textbf{std.error:} \\newline \\textbf{statistic:} \\newline \\textbf{p.value}",
    booktabs = T
  ) %>%
  kableExtra::column_spec(1, bold = TRUE)
```

```{r plot binford model, warning=FALSE, fig.height=7, fig.cap="\\label{fig:binford_model_plot}Diagnostische Plots für das Modell auf Grundlage der von Binford vorgeschlagenen Variablenauswahl. \\newline  \\textbf{Residuals vs Fitted:} Streuung der Residuen in Abhängigkeit von der Modellvorhersage. Kann als Indikator für nicht lineare Trends dienen. \\newline \\textbf{Normal Q-Q:} Sortierte Residuenwerte abgetragen auf die theoretischen Quantile einer Normalverteilung. Zeigt, inwiefern die Residuenverteilung der Normalverteilung entspricht. \\newline \\textbf{Scale-Location:} Vergleiche Residuals vs Fitted. Die Umskalierung erlaubt es, die Homogenität der Residuenvarianz (Homoskedastizität) besser zu beurteilen.  \\newline \\textbf{Residuals vs Leverage:} Standardisierte Residuenwerte abgetragen auf ein Maß zur Einschätzung des Einflusses auf das Modellergebnis. Dient zum Identifizieren von einflussreichen Ausreißern. ^[Zum Verständnis der diagnostischen Plots: http://data.library.virginia.edu/diagnostic-plots/ [16.8.2017]]"}
opar <- par(mfrow=c(2,2)) 
plot(binford_model)
par(opar) 
```

Tabelle \ref{tab:binford_model_result} enthält Koeffizienten und Fehlermargen des erzeugten Modells. Die Koeffizienten weichen aus mir unbekanntem Grund von den von Binford errechneten ab. Abbildung \ref{fig:binford_model_plot} zeigt die vier diagnostischen Standardplots, die die Funktion `plot.lm()` aus stats bereitstellt. Das Modell scheint eine hohe Erklärungspotenz zu besitzen.
<!-- TODO: Mehr dazu! -->

```{r}
binford_model2 <- binford_model
binford_model$coefficients <- c()
```

Ich möchte nun versuchen, selbst ein Modell für die Variable AREA zu erstellen. Das Ergebnis der Multiplen Regression ist dabei einerseits abhängig von den Eingabevariablen, andererseits aber auch -- zumindest wenn sie nicht vollständig unkorreliert sind -- von deren Eingabereihenfolge. Da im Fall der vorliegenden Analyse keine theoretischen oder sachlogischen Überlegungen Eingang finden sollen, die die Variablenauswahl determinieren würden, müssten eigentlich alle Permutationen von Auswahl und Reihenfolge betrachtet werden. Bei `r ncol(sel2) - 1` unabhängigen Variablen ist allerdings die Anzahl allein der Permutationen weit größer als praktisch in irgendeiner Form verarbeitbar ($200! \approx 7.887*10^{374}$). Aus diesem Grund muss auf ein Verfahren der Schrittweisen Regressionsanalyse zurückgegriffen werden, das mittels Prüfgrößen selbständig und in verhältnismäßig wenigen Iterationsschritten eine Variablenauswahl trifft^[@backhaus_multivariate_2008, 100-105.].  

Ich habe mich hier für die Implementierung eines solchen Verfahrens in der Funktion `stepAIC()` des R Pakets MASS^[@venables_modern_2002, 172-177.] entschieden. `stepAIC()` erreicht die Modellreduktion durch schrittweise Minimierung der Prüfgröße AIC (Akaike Information Criterion -- $\mathit{AIC} = -2 * \mathit{maximierte} \mathit{Log-Likelihood} + 2 * \# Parameter$), die man vereinfacht als Maß für die Passgenauigkeit eines statistischen Modells verstehen kann. `stepAIC()` benötigt dafür ein berechnetes Eingangsmodell, das nach Möglichkeit nah am besten Ergebnismodell liegen sollte, sowie Modelldefinitionen jeweils eines maximal und minimal komplexen Ergebnismodells. Da das Ausgangsmodell mit `r nrow(sel2)` Beobachtungen und `r ncol(sel2)` Variablen in diesem Kontext als komplex gelten darf, möchte ich mich zunächst an folgende Empfehlung der Autoren halten, und dem Algorithmus stattdessen nur dieses Initialmodell zur Verfügung stellen.

> If a large model is selected as the starting point, the scope and scale arguments have generally reasonable defaults, but for a sma1l model where the process is probably to be one of adding terms, they will usually need both to be supplied. 
>  
> -- [@venables_modern_2002, 175.]

Zunächst erfolgt die Berechnung des Ausgangsmodells:

```{r create initial model, echo = TRUE, cache=TRUE}
initial_model <- lm(area ~ ., data = sel2)
```

```{r plot initial model, warning=FALSE, fig.height=7, fig.cap="\\label{fig:initial_model_plot}Diagnostische Plots für das Ausgangsmodell mit allen Variablen."}
opar <- par(mfrow=c(2,2)) 
plot(initial_model)
par(opar) 
```

```{r identify bad observations}
# visual obersvations at the plots allow identification of outliers:
outies <- c(298, 306, 308)
outies_names <- main$X[outies]
```

Für geringe Arealgrößen geben die Residuen Anlass zur Annahme, dass zwischen abhängiger und unabhägigen Variablen eine nicht-lineare Beziehung besteht, die durch das Modell schlecht abgebildet wird (siehe Abbildung \ref{fig:initial_model_plot}). Einige Beobachtungen (`r paste0(paste0(outies, ": ", outies_names), collapse = ", ")`) treten als klare Ausreißer auf, die ich zunächst allerdings ignorieren möchte. 

Stattdessen ein erster Durchlauf der automatischen, schrittweisen Modellreduktion: 

```{r stewise multiple regression, dependson="create first model", cache=TRUE, message=FALSE, echo=TRUE}
model1 <- MASS::stepAIC(
  initial_model, 
  trace = FALSE
)
```

```{r plot model1, dependson="stewise multiple regression", cache=TRUE, warning=FALSE, fig.height=7, fig.cap="\\label{fig:model1_plot}Diagnostische Plots für das Modell nach dem ersten Durchlauf von `stepAIC()`."}
opar <- par(mfrow=c(2,2)) 
plot(model1)
par(opar) 
```

```{r anova table of stepAIC}
model1$anova %>% as.data.frame() %>% dplyr::rename("Dev" = "Deviance") %>% knitr::kable(
    format = "latex",
    caption = "\\label{tab:model1_anova}ANOVA Komponente des Ergebnismodelldatentyps von `stepAIC()`.  Zeigt die schrittweise Entfernung von Variablen zur Reduktion der Modellkomplexität und zugehörige, diagnostische Prüfgrößen. \\newline \\textbf{Step:} Variable, die in diesem Schritt entfernt oder hinzugefügt wurde \\newline \\textbf{Df -- degrees of freedom:} Anzahl der Freiheitsgrade ('Anzahl der Werte in der abschließenden Berechnung einer Statistik, die frei variieren können') \\newline \\textbf{Dev -- Deviance:} Unterschied in der Summe der Fehlerquadrate gegenüber dem vorangegangenen Schritt \\newline \\textbf{Resid. Df -- residual degrees of freedom:} Gesamtanzahl der Freiheitsgrade minus Freiheitsgrade des Modells \\newline \\textbf{Resid. Dev -- residual deviance:}  \\newline \\textbf{AIC -- Akaike information criterion:} siehe Text",
    booktabs = T
  ) %>%
  kableExtra::column_spec(1, bold = TRUE, width = "6em") %>%
  kableExtra::column_spec(2, width = "3em") %>%
  kableExtra::column_spec(3, width = "2em") %>%
  kableExtra::column_spec(4, width = "3em") %>%
  kableExtra::column_spec(5, width = "3em") %>%
  kableExtra::column_spec(6, width = "3em")
```

Tabelle \ref{tab:model1_anova} zeigt die Reduktionsschritte. `r nrow(model1$anova)` Variablen wurden von `stepAIC()` entfernt, dann allerdings kam der Prozess in diesem Durchlauf zum halten. Der Vergleich des *Residuals vs Leverage* Plots in Abbildung \ref{fig:initial_model_plot} und Abbildung \ref{fig:model1_plot} legt nahe, dass sich die durchschnittliche Wirkung individueller Beobachtungen auf das Gesamtergebnis verringert hat. Anzunehmen ist, dass Variablen mit großer Variablität entfernt wurden. Der Vergleich mit Abbildung \ref{fig:binford_model_plot} legt nahe, dass sich dieser Trend bei weiterer Reduktion des Modells fortsetzen wird.

Die Reduktion auf `r ncol(sel2) - nrow(model1$anova)` Variablen ist noch nicht ausreichend, um an die deskriptive Einfachheit des Binford-Modells heranzureichen. Die Minimierung des AIC-Werts ist offensichtlich kein ausreichend starkes Optimierungskriterium:

> This suggests, correctly, that selecting terms on the basis of AIC can be somewhat permissive in its choice of terms, being roughly equivalent to choosing an F-cutoff of 2.  
>  
> -- [@venables_modern_2002, 176.]

Wir können nun fortfahren, indem wir entweder das k-Attribut in `stepAIC()` (*the multiple of the number of degrees of freedom used for the penalty*) erhöhen und den Prozess erneut starten, oder mittels F-Statistik schrittweise jene Variablen entfernen, die keinen signifikanten Einfluss auf das Ergebnismodell nehmen. Um diese zu identifizieren, steht in MASS die Funktion `dropterm()` bereit.  

<!-- https://www.r-bloggers.com/manual-variable-selection-using-the-dropterm-function/ --> 

```{r dropterm example code, eval=FALSE, echo=TRUE}
MASS::dropterm(model1, test = "F")
```

Tabelle \ref{tab:dropterm_example}

```{r dropterm example table, cache=TRUE}
MASS::dropterm(model1, test = "F") %>%
  as.data.frame() %>%
  magrittr::extract(1:10, ) %>%
  tibble::rownames_to_column() %>%
  dplyr::select(
    -AIC
  ) %>%
  dplyr::mutate_at(
    c("Sum of Sq", "RSS", "F Value"),
    dplyr::funs(round(., 2))
  ) %>%  
  dplyr::mutate_at(
    c("Pr(F)"),
    dplyr::funs(round(., 4))
  ) %>%
  dplyr::mutate_all(
    dplyr::funs(as.character(.))
  ) %>%
  # add decorative ... at the beginning and end
  rbind(
    ., 
    data.frame(
      rowname = "...", Df = "...", `Sum of Sq` = "...", RSS = "...",
      `F Value` = "...", `Pr(F)` = "...", check.names = F
    )
  ) %>%
  knitr::kable(
    format = "latex",
    caption = "\\label{tab:dropterm_example}dropterm Tabelle: Maße der Modellgüte für verschiedene Variablen \\newline \\textbf{Df - degrees of freedom:} siehe oben \\newline \\textbf{Sum of Sq -- sum of squared deviations:} Abweichung der individuellen Werte vom Mittelwert aller Werte \\newline \\textbf{RSS -- residual sum of squares:} Abweichung der Vorhersagen für die abhängige Variable von ihren tatsächlichen Werten \\newline \\textbf{AIC -- Akaike information criterion:} siehe Text \\newline \\textbf{F Value:} Einganswert des F-Tests \\newline \\textbf{Pr(F) -- probability of F-Value:} Maß für die Wahrscheinlichkeit des F-Werts. Kleine Werte sind ein Indikator für eine wichtige Variable",
    booktabs = T
  ) %>%
  kableExtra::column_spec(1, bold = TRUE)
```

```{r}
MASS::dropterm(model1, test = "F") -> ha

gu <- ha %>% tibble::as.tibble() %>%
  dplyr::mutate(
    names = rownames(ha)
  ) %>%
  # dplyr::top_n(
  #   -10, `Pr(F)`
  # ) %$%
  dplyr::filter(
    `Pr(F)` < 0.00001
  ) %$%
  names

shu <- main %>%
  dplyr::select(
    area, gu
  )

model3 <- lm(area ~ ., data = shu)



```

```{r}
#MASS::stepAIC(model3)
```

## Vergleich der Ergebnismodelle

Vergleichen wir nun also kurz
