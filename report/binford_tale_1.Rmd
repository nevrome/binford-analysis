---
output: 
  pdf_document:
    pandoc_args: [
      "-V", "classoption=twocolumn"
    ]
    toc: yes 
    fig_caption: yes
    latex_engine: xelatex
bibliography: bibliography.bib
mainfont: "Arial"
csl: deutsches-archaologisches-institut.csl
---

```{r load libraries, echo=FALSE}
library(magrittr)
library(ggplot2)
# only magrittr and ggplot should be loaded here - everything else should be explicitly mentioned via package::function 
```

# Modelle zur Beschreibung der Ausbreitungsarealgröße von Jäger- und Sammlergruppen

## Problemstellung

Im 5. Kapitel "Designing Frames of Reference and Exploring Projections" beschreibt Binford unter anderem eine Methode, Vorhersagen zu Attributen von Jäger- und Sammlergruppen in globalem Maßstab auf Grundlage von ethnographischen und naturräumlichen Daten treffen und über Projektion auf Karten visualisieren zu können. Im Abschnitt "Projecting Hunter-Gatherer Populations to the Entire Earth" gibt es wiederum einen Unterabschnitt "Using Relational Projections as Frames of Reference", der das Vorgehen anhand eines Beispiels illustriert. Binford schreibt: 

> If I can develop continously scaled equations that summarize the relationship between the properties of hunter-gatherer systems and suites of environmental variables, it is likely that these equations could be used to project estimates for habitats from which there are few, if any, actual cases of hunter-gatherers documented in the resent past. But since such equations summarize interactive ecological relationships that are not confined to particular time periods, they may furnish strong clues about hunter-gatherer organizational variability that will provide a strong platform for subsequent theory building.  
> 
> -- @binford_constructing_2001, 154.

Das Beispiel konzentriert sich auf die Variable *area* -- die Größe des Areals, das von einer Jäger- und Sammlergruppe relativ exklusiv genutzt wird gemessen in Vielfachen von 100km². Mittels multipler Regression auf Grundlage des Gruppendatensatzes kommt Binford zu folgender Gleichung \ref{eq:area_multi} (bzw. umgeformt Gleichung \ref{eq:area_multi_log}), die die abhängige Variable *area* in Relation zu mehreren unabhängigen Variablen (siehe Tabelle \ref{tab:variable_description_1}) beschreibt:

\begin{equation} \label{eq:area_multi}
\begin{aligned}
\mathit{area} = \\
    & 10 \mathbin{\char`\^} [3.421431 + \\ 
    & (0.004732 * \mathit{hunting}) + \\
    & (-0.387229 * \mathit{lbio5}) + \\
    & (0.186574 * \mathit{lcoklm}) + \\
    & (-0.110286 * \mathit{lrunoff}) + \\
    & (0.175157 * \mathit{watrgrc}) + \\
    & (-0.164604 * \mathit{medstab}) + \\
    & (-0.743144 * \mathit{perwltg}) + \\
    & (0.004706 * \mathit{rlow}) + \\
    & (-0.080339 * \mathit{rungrc}) + \\
    & (0.024755 * \mathit{sdtemp})]
\end{aligned}
\end{equation}

```{r table of variables in binfords model}
# create table data
tibble::tribble(
  ~colA,  ~Beschreibung, ~Einheit, ~Referenz,
  "area", "Größe des Areals, das von einer Jäger- und Sammlergruppe relativ exklusiv genutzt wird", "100km²", "117",
  "larea", "siehe area", "log10(100km²)", "",
  "lbio5", "Primäre (pflanzliche) Biomasse", "log(kg/m^2)", "85",
  "lcoklm", "Distanz zur nächstgelegenen, marinen Küste", "log10(km)", "154",
  "gatherin", "Ernährungsanteil pflanzlicher, terrestrischer Ressourcen", "%","117",
  "hunting", "Ernährungsanteil tierischer, terrestrischer Ressourcen", "%", "117",
  "kmov", "Summe der Distanz, die eine durchschnittliche Familieneinheit in einem Jahr zurücklegt", "km/yr", "117",
  "lati", "Breitengrad auf einer Idealkugelprojektion (rectifying latitude)", "°", "",
  "rlow", "Niederschlagsmenge im trockensten Monat des Jahres", "Millimeter", "70",
  "medstab", "Indikatorgröße für die Ähnlichkeit zu mediterranem Klima berechnet aus Proxies zu Temperatur und Niederschlag", "keine Einheit", "72",
  "lnagp", "Net above-ground productivity -- Zuwachs der Biomasse in einem Habitat durch Photosynthese und Wachstum", "g/m^2/yr", "79", 
  "nicheff", "Niche effectiveness -- Verhältnis der tatsächlichen Bevölkerungsdichte zu einer modellbasierten Vorhersage der Bevölkerungsdichte, die Binford in Kapitel 10 formuliert", "keine Einheit", "373",
  "lnpop", "Größe der untersuchten Bevölkerung", "log(Anzahl)", "117",
  "perwret", "Anteil des Wachstumszeitraum in dem der Boden Wasser gespeichert vorhält", "%", "79",
  "perwltg", "Anteil des Wachstumszeitraum in dem die Wasserverfügbarkeit unter dem pflanzlichen Welkepunkt liegt", "%", "79", 
  "rungrc", "Anzahl der Monate im Wachstumszeitraum in denen der RUNOFF-Wert > 0", "Anzahl", "79",
  "lrunoff", "Wasser, das durch Abfluss für die Nutzung durch Pflanzen verloren geht", "log(mm)", "79",
  "sdtemp", "Standardabweichung der mittleren Monatstemperatur", "keine Einheit", "70",
  "temp", "Temperateness -- Indikatorgröße für die Ausgeglichenheit der Monatstemperatur", "keine Einheit", "59",
  "watrgrc", "Anzahl der Monate im Wachstumszeitraum, in denen Wasser im Boden gespeichert bleibt", "Anzahl", "79"
) %>%
    dplyr::rename(
    " " = "colA"
  ) %>%
  # table setup and settings
  knitr::kable(
    format = "latex",
    caption = "\\label{tab:variable_description_1}Kurzbeschreibung der Variablen in Binfords Ergebnismodell und dem von mir erarbeiteten, finalen Modell. Die Spalte Referenz enthält die Seitenzahl in \\textit{Constructing Frames of Reference}, wo die jeweilige Variable eingeführt wird.",
    booktabs = T
  ) %>%
  kableExtra::column_spec(1, bold = TRUE) %>%
  kableExtra::column_spec(2, width = "14em") %>%
  kableExtra::kable_styling(font_size = 9)
```

Binford hat seine Analyse in SPSS (Version 6.1.2) ausgeführt. Ein Skriptprotokoll der Analysesession liegt mir nicht vor. Um die Ergebnis in Form der Modellgleichung zu reproduzieren, werde ich nun also zunächst versuchen, das Vorgehen so gut wie möglich nachzuvollziehen. Dafür steht mir eine hoffentlich gleiche oder zumindest hochgradig ähnliche Version des oben beschriebene Gruppendatensatz zu Verfügung. Ich weiß weiterhin, dass Binford sein Modell mit der Methode schrittweiser, Multipler Regression ermittelt hat. Unabhängige Variablen, die sich kollinear zu anderen unabhängigen Variablen verhalten, hat er entfernt. Die abschließende Entscheidung über das beste Modell hat er unter Beachtung der Indikatorgrößen $R^2$ und Standardfehler getroffen. Diese Angaben sind leider nicht hinreichend präzise.

## Datensatz

Ein wesentliches Wissensdefizit besteht bezüglich der Information, in welcher Reihenfolge und mit welcher Rechtfertigung in den Schritten der Multiplen Regression Variablen jeweils entfernt wurden. Schon die Angabe, welche Variablen im Ausgangsdatensatz berücksichtigt wurden, ist unscharf. Immerhin: Da Multiple Regression nur auf Variablen der Intervall- oder Verhältnisskala (zusammen auch Kardinalskala oder metrisch skalierte Variablen) anwendbar ist, ist eine erste Eingrenzung möglich. Der Metadatensatz LRBkey verfügt hierzu über die Spalte *type*, die zu jeder Variable ein Skalenniveau angibt. Leider wird nur zwischen "categorical" und "ordinal" unterschieden. Dabei werden alle Variablen jenseits der Nominalskala als "ordinal" angesprochen. Das genügt nicht, um automatisiert alle intervall- und verhältnisskalierten Variablen auszuwählen. Aus diesem Grund habe ich selbst die Spalte *type_exp* im Metadatensatz hinzugefügt, und nach meiner Einschätzung auf Grundlage des Wertebereichs und der Beschreibung eine Zuordnung zu einem der vier Skalenniveaus "nominal", "ordinal", "interval" und "ratio" vorgenommen. Tabelle \ref{tab:variable_key_example} illustriert die Unterschiede zwischen der vorhandenen und meiner neu unternommenen Zuordnung für ein paar zufällig ausgewählte Variablen. Abbildung \ref{fig:level_of_meas_bar} zeigt, wie sich die Reevaluation durch die in *type_exp* deutlich akzentuiertere Verteilung der Skalenniveaus auswirkt. 

```{r load binford data, cache=TRUE, message=FALSE, warning=FALSE}
# load data
# TODO: setup correct connections when all datasets are where they are supposed to be
key <- readr::read_csv("../data-raw/LRBkey.csv") #%>%
  #dplyr::rename("variable" = "X1")
main <- binford::LRB
```

```{r variable type example table, cache=TRUE}
# create random subset of key table
key[250:262, ] %>%
  # select showvars
  dplyr::select(variable, description, type, type_exp) %>%
  # add decorative ... at the beginning and end
  rbind(
    data.frame(variable = "...", description = "...", type = "...", type_exp= "..."), 
    .,
    data.frame(variable = "...", description = "...", type = "...", type_exp= "...")
  ) %>%
  # table setup and settings
  knitr::kable(
    format = "latex",
    caption = "\\label{tab:variable_key_example}Auszug aus der Metatabelle zum Gruppendatensatz. Skalenniveauklassifizierung in den Spalten \\textit{type} und \\textit{type\\_exp}.",
    booktabs = T
  ) %>%
  kableExtra::column_spec(1, bold = TRUE) %>%
  kableExtra::column_spec(2, width = "14em") %>%
  kableExtra::kable_styling(font_size = 9)
```

```{r type classification distribution plot, cache=TRUE, fig.cap="\\label{fig:level_of_meas_bar}Verteilung der Skalenniveauzuordung in den Variablen *type* und *type_exp* des Metatdatensatzes. *type_exp* habe ich hinzugefügt, um Variablen automatisiert nach ihrer Skalenniveauzuordnung auswählen zu können. Die Klassenzuordnung in *type* ist farblich auf *type_exp* abgetragen."}
# prepare factor levels of type_exp column
key$type_exp <- factor(
  key$type_exp, 
  levels =  c("nominal", "ordinal", "interval", "ratio", "unknown")
)

# barplot of count of type_exp
type_exp_bar <- key %>%
  ggplot(aes(x = type_exp, fill = type)) +
  geom_bar() + 
  theme_bw(base_size = 16) +
  scale_fill_manual(values = c("red", "black")) +
  ylab("") +
  guides(fill = FALSE) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))

# prepare factor levels of type column
key$type <- factor(
  key$type,
  levels <- c("categorical", "ordinal")
)

# barplot of count of type
type_bar <- key %>%
  ggplot(aes(x = type, fill = type)) +
  geom_bar() +
  theme_bw(base_size = 16) +
  scale_fill_manual(values = c("red", "black")) +
  ylab("Anzahl der Variablen") +
  guides(fill = FALSE) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))

# combine plots
cowplot::plot_grid(type_bar, type_exp_bar)
```

```{r apply selection, cache=TRUE}
# get interval and ratio variables 
inter_ratio_vars <- key %>%
  dplyr::filter(
    type_exp %in% c("interval", "ratio")
  ) %$%
  variable

# select only them for further analysis
sel1 <- main %>% 
  dplyr::select(dplyr::one_of(inter_ratio_vars))
```

Auf dieser Grundlage ist es jetzt also möglich, einen Ausgangsdatensatz zusammenstellen, der zwar alle `r nrow(sel1)` Gruppen aber nur die `r ncol(sel1)` interval- und ratioskalierten Variablen enthält. Hier fällt allerdings gleich ein erstes Defizit dieser Selektion auf: Einige Variablen haben sehr wenige Einträge, d.h. der Wert der entsprechenden Variable wurde nur für wenige Gruppen aufgenommen. Abbildung \ref{fig:is_na_bar} enthält ein Histogramm der Fehlstellenanzahl. 

```{r na histogram, warning=FALSE, fig.cap="\\label{fig:is_na_bar}Verteilung der Fehlstellenanzahl in metrisch skalierten Variablen und den zugehörigen Beobachtungen (Gruppen). Die Klassenbreite der Histogramme beträgt 15. Variablen und Gruppen ohne Fehlstellen wurden für die Visualisierung ausgeschlossen. Die horizontale, rote Linie im Variablenhistogramm markiert die Grenze oberhalb der Variablen aus der weiteren Analyse entfernt wurden."}
# get data.frame with number of na per variable
na_pro_var <- sel1 %>% 
  purrr::map(
    ~sum(is.na(.))
  ) %>% 
  as.data.frame() %>% 
  tidyr::gather() %>%
  # remove variables with zero na
  dplyr::filter(
    value != 0
  )

# get data.frame with number of na per observation
na_pro_obs <- sel1 %>% t %>% as.data.frame() %>%
  purrr::map(
    ~sum(is.na(.))
  ) %>% 
  as.data.frame() %>% 
  tidyr::gather() %>%
  # remove variables with zero na
  dplyr::filter(
    value != 0
  )

# define threshold above which variables will be removed below
na_vars_removal_threshold <- 1/3

# plot histogram for variables
na_vars_plot <- na_pro_var %>%
  ggplot(aes(x = value)) +
  geom_histogram(binwidth = 15, fill = "black") +
  geom_vline(aes(xintercept = na_vars_removal_threshold*ncol(sel1)), color = "red", size = 1) + 
  theme_bw(base_size = 16) +
  ylab("Anzahl der Variablen") +
  xlab("Anzahl der Fehlstellen") +
  coord_flip() +
  xlim(-20, 340)

# plot histogramm for observations
na_obs_plot <- na_pro_obs %>%
  ggplot(aes(x = value)) +
  geom_histogram(binwidth = 15, fill = "black") +
  theme_bw(base_size = 16) +
  ylab("Anzahl der Gruppen") +
  xlab("") +
  coord_flip() +
  xlim(-20, 340)

# combine plots
cowplot::plot_grid(na_vars_plot, na_obs_plot)
```

```{r prepare na values to be printed}
# calculate proportions for text
without_na <- ncol(sel1) - nrow(na_pro_var)
without_na_percent <- round(without_na/ncol(sel1)*100)
```

```{r remove na variables}
# remove vars with more na values than 1/3 * total amount of variables
na_vars_part <- na_pro_var %>%
  dplyr::filter(
    value > (na_vars_removal_threshold)*ncol(sel1)
  )

sel2 <- sel1 %>%
  dplyr::select(
    -dplyr::one_of(na_vars_part$key)
  )
```

Immerhin `r without_na` der `r ncol(sel1)` ($\approx$ `r without_na_percent`%) Variablen besitzen überhaupt keine Lehrstellen. Der Datensatz ist bemerkenswert vollständig. Ich habe mich entschieden, alle `r nrow(na_vars_part)` Variablen, bei denen mehr als `r paste(MASS::fractions(na_vars_removal_threshold))` der Werte fehlen aus der Analyse auszuschließen, um Problemen bei der Regressionsanalyse vorzubeugen. In Abbildung \ref{fig:is_na_bar} ist die Demarkationslinie rot eingetragen. Bei den gruppenbezogenen Beobachtungen ist das Bild insgesamt ausgeglichener: Für alle Gruppen liegt eine große Menge an Werten vor. Hier sind keine Änderungen erforderlich.

In einem letzten Schritt muss nun noch die Variable *area* durch die Variable *larea* ausgetauscht werden. Binford gibt im Buch zwar die Modellergebnisgleichung für *area* an, das errechnete Modell bezieht sich aber auf den Logarithmus zur Basis 10 von *area* (siehe Umformung von Gleichung \ref{eq:area_multi} zu \ref{eq:area_multi_log}). Der damit vorbereitete Arbeitsdatensatz wird im folgenden als `sel3` bezeichnet. 

\begin{equation} \label{eq:area_multi_log}
\begin{aligned}
\log _{10} \mathit{area} = \\
\mathit{larea} = \\
    & 3.421431 + \\ 
    & (0.004732 * \mathit{hunting}) + \\
    & (-0.387229 * \mathit{lbio5}) + \\
    & (0.186574 * \mathit{lcoklm}) + \\
    & (-0.110286 * \mathit{lrunoff}) + \\
    & (0.175157 * \mathit{watrgrc}) + \\
    & (-0.164604 * \mathit{medstab}) + \\
    & (-0.743144 * \mathit{perwltg}) + \\
    & (0.004706 * \mathit{rlow}) + \\
    & (-0.080339 * \mathit{rungrc}) + \\
    & (0.024755 * \mathit{sdtemp})
\end{aligned}
\end{equation}

```{r}
# replace area with larea  
sel3 <- sel2 %>%
  dplyr::rename(
    "larea" = "area"
  ) %>% 
  dplyr::mutate(
    larea = log10(larea)
  )
```

## Multiple Regression

Multiple Lineare Regression ist ein Verfahren der Multivariaten Statistik, das die Erklärung und Vorhersage einer abhängigen Variable durch mehrere unabhängige Variablen erlaubt ^[@backhaus_multivariate_2008, 52-53/64-65., @de_veaux_stats:_2012, 784-812.]. Die Regressionsparameter (Koeffizienten) können wie bei der Einfachen Regressionsanalyse durch Reduktion der Fehlerquadrate berechnet werden. In einem ersten Schritt möchte ich das Modell von Binford nachstellen, indem ich seine Auswahl an Eingabevariablen übernehme und die Regression mittels der Funktion `lm()` aus dem R Basispaket stats darauf anwende. 

```{r recreate binford model, echo=TRUE, cache=TRUE}
binford_model <- lm(
  larea ~ hunting + lbio5 + lcoklm + 
          lrunoff + watrgrc + medstab + perwltg +
          rlow + rungrc + sdtemp, 
  data = sel3
)
```

```{r binford model estimate table, cache=TRUE, dependson="recreate binford model"}
# create nice data.frame with model coefficent information
var_vals <- binford_model %>%
  broom::tidy() %>%
  dplyr::mutate_if(
    is.numeric,
    dplyr::funs(round(., 3))
  ) %>%
  dplyr::rename(
    " " = "term"
  )

# prepare output table with extensiv description
var_vals %>%
  knitr::kable(
    format = "latex",
    caption = "\\label{tab:binford_model_result}Ergebniszusammenfassung des mit Binfords Variablenauswahl reproduzierten Modells für die einzelnen Koeffizienten. Alle Werte sind auf drei Nachkommastellen gerundet \\newline \\textbf{estimate -- Koeffizient:} Koeffizienten(schätzung) des Ergebnismodells (Intercept und Variablenslopes). \\newline \\textbf{std.error -- Standardfehler:} Maß für die Präzision der Schätzung für den Wert des Koeffizienten. Bei einer Variable, die gut für die Vorhersage der abhängigen Variable geeignet ist, sollte der Standardfehler in Relation zum Koeffizienten klein sein.\\newline \\textbf{statistic -- t-Wert:} Anzahl der Standardabweichungen, die den Koeffizienten von Null trennt. Der Betrag des Wertes sollte (auch in Relation zum Standardfehler) groß sein um die Nullhypothese 'keine Relation der Variablen' verwerfen zu können.\\newline \\textbf{p.value -- p-Wert:} p-Wert der t-Statistik. Wahrscheinlichkeit, dass eine Beobachtung auftritt, die gleich oder größer als der t-Wert ist. Ein kleiner p-Wert zeigt an, dass die Wahrscheinlichkeit einer zufälligen Enstehung dieses Modellergebnisses gering ist. Die Relation zwischen abhängiger und unabhängiger Variable ist damit signifikant.",
    booktabs = T
  ) %>%
  kableExtra::column_spec(1, bold = TRUE)
```

```{r binford model estimate table 2, cache=TRUE, dependson="recreate binford model"}
# create nice data.frame with model quality information
mod_vals <- binford_model %>%
  broom::glance() %>%
  tidyr::gather(var, value) %>% 
  dplyr::mutate(
    var2 = c(var[7:11], rep(NA, 6)),
    value2 = c(value[7:11], rep(NA, 6))
  ) %>%
  # value df is removed like this - is useless here anyway
  magrittr::extract(1:5,) %>%
  dplyr::mutate_if(
    is.numeric,
    dplyr::funs(round(., 3))
  ) %>% dplyr::mutate_if(
    is.numeric,
    as.character
  ) %>%
  dplyr::rename(
    " " = "var",
    " " = "var2",
    "value" = "value2"
  )

# vestige from when there were two empty cells due to magrittr::extract(1:6,)
mod_vals[is.na(mod_vals)] <- ""

# prepare output table with extensiv description
mod_vals %>%
  knitr::kable(
    format = "latex",
    caption = "\\label{tab:binford_model_result_2}Ergebniszusammenfassung des mit Binfords Variablenauswahl reproduzierten Modells für das Gesamtmodell. Alle Werte sind auf drei Nachkommastellen gerundet. \\newline \\textbf{r.squared -- $R^2$ -- Bestimmtheitsmaß:} $R^2$ ist ein Maß für die Güte der Modelleinpassung. Es gibt den Anteil der Varianz der abhängigen Variablen wieder, der durch das lineare Modell erklärt wird. Der Wert liegt zwischen 0 (kein linearer Zusammenhang) und 1 (perfekter linearer Zusammenhang). Ein hoher Wert ist ein Indikator für ein gutes Modell.\\newline \\textbf{adj.r.squared -- korrigiertes Bestimmtheitsmaß:} $R^2$ korrigiert unter Beachtung der Anzahl unabhängiger Variablen. $R^2$ wird bei zunehmender Anzahl an Variablen größer und muss entsprechend bei Multipler Regression normiert werden. \\newline \\textbf{sigma -- Residual Standard Error:} Durchschnittliche Abweichung der Modellvorhersage für die abhängige Variable von den tatsächlich gemessenen Werten. Bei einem guten Modell sollte der Wert gering sein. \\newline \\textbf{statistic und p.value} Siehe Tabelle \\ref{tab:binford_model_result}. Hier beziehen sich die Werte auf das Gesamtmodell. \\newline \\textbf{logLik -- Log\\-Likelihood, AIC -- Akaike Information Criterion und BIC -- Bayesian Information Criterion} Maße für die Güte der Modelleinpassung. \\newline \\textbf{deviance} Maß für die Distance zweier Modelle. Hier als Maß für die Güte der Modelleinpassung indem das Ergebnismodell mit dem Null\\--Modell (s.u.) verglichen wird. \\newline \\textbf{df.residual -- Anzahl der Freiheitsgrade} Berechnet sich aus der Anzahl der Beobachtungen abzüglich der Anzahl der schätzbaren Koeffizienten. Insofern handelt es sich um die Anzahl der 'überflüssigen' Messwerte, die zur Berechnung der Modellparameter nicht erforderlich wären.",
    booktabs = T
  ) %>%
  kableExtra::column_spec(1, bold = TRUE) %>%
  kableExtra::column_spec(3, bold = TRUE)
```

```{r plot binford model, warning=FALSE, cache=TRUE, dependson="recreate binford model", fig.height=7, fig.cap="\\label{fig:binford_model_plot}Diagnostische Plots für das mit Binfords Variablenauswahl reproduzierte Modell. \\newline \\textbf{Residuals vs Fitted:} Streuung der Residuen in Abhängigkeit von der Modellvorhersage. Kann als Indikator für nicht lineare Trends dienen. \\newline \\textbf{Normal Q-Q:} Sortierte Residuenwerte abgetragen auf die theoretischen Quantile einer Normalverteilung. Zeigt, inwiefern die Residuenverteilung der Normalverteilung entspricht. \\newline \\textbf{Scale-Location:} Vergleiche Residuals vs Fitted. Die Umskalierung erlaubt es, die Homogenität der Residuenvarianz (Homoskedastizität) besser zu beurteilen.  \\newline \\textbf{Residuals vs Leverage:} Standardisierte Residuenwerte abgetragen auf *Leverage*, ein Maß zur Einschätzung des Einflusses auf das Modellergebnis. Dient zum Identifizieren von einflussreichen Ausreißern. ^[Zum Verständnis der diagnostischen Plots: http://data.library.virginia.edu/diagnostic-plots [16.8.2017]]"}
# diagnostic plots
opar <- par(mfrow=c(2,2)) 
plot(binford_model)
par(opar) 
```

```{r identify bad observations for binford model}
# visual obersvations at the plots allow identification of outliers:
outies_binford_model <- c(3, 14, 45, 338)
outies_binford_model_names <- main$X[outies_binford_model]
```

Tabelle \ref{tab:binford_model_result} enthält Koeffizienten und zugehörige Kennwerte des erzeugten Modells ^[Ich habe versucht möglichst viele Kennwerte nachzuvollziehen. Siehe dazu für die Tabellen \ref{tab:binford_model_result} und \ref{tab:binford_model_result_2} @de_veaux_stats:_2012, 785 & 792-794. und \url{https://feliperego.github.io/blog/2015/10/23/Interpreting-Model-Output-In-R} [23.8.2017] sowie für Tabelle \ref{tab:dropterm_example} @gordon2015regression und @de_veaux_stats:_2012, 792-793.]. Ein Vergleich der Werte mit jenen in Gleichung \ref{eq:area_multi_log} ergibt, dass die Koeffizienten von den von Binford errechneten abweichen. Ich nehme an, dass der Regressionsalgorithmus in SPSS geringfügig anders implementiert ist als derjenigen in `lm()` oder SPSS die Regression nicht mittels einfacher Reduktion der Fehlerquadrate durchführt. Unter dem Hyperonym *Robuste Regression* werden verschiedene andere Verfahren diskutiert ^[@Jann2010]. Da die Werte nur geringfügig divergieren und Größenordnung sowie Vorzeichen übereinstimmen, gehe ich von einer nicht relevanten Abweichung aus, die ich hier nicht weiter diskutieren möchte. Tabelle \ref{tab:binford_model_result_2} gibt einige Kennwerte der Modellgüte und Abbildung \ref{fig:binford_model_plot} die vier diagnostischen Standardplots wieder, die die Funktionen `summary.lm()` und `plot.lm()` aus stats bereitstellen. Das Modell scheint ein hohes Erklärungspotential zu besitzen, die abhängige Variable *area* also gut zu beschreiben. Starke Ausreißer gibt es nicht -- die überwiegende Mehrzahl der Beobachtungen wird durch das Modell gut erklärt. Nur einzelne Beobachtungen zeigen Auffälligkeiten: `r paste0(paste0(outies_binford_model, ": ", outies_binford_model_names), collapse = ", ")`. *watrgrc* ist nicht gut zur Beschreibung von *area* geeignet.

Ich möchte nun versuchen, selbst ein Modell für die Variable *area* zu erstellen. Dabei sind eigentlich einige Aspekte zu beachten ^[@de_veaux_stats:_2012, 788-790.], mit denen ich in diesem Experiment aber bewusst sehr inkonsequent umgehen möchte:

1. **Linearität:** Zwischen der abhängigen und jeder einzelnen unabhängigen Variable sollte eine lineare, geradlinige Beziehung bestehen ("straight enough condition").
2. **Unabhängigkeit:** Die Fehlerverteilung der unabhängigen Variablen sollte unabhängig voneinander sein ("randomization condition").
3. **Varianzäquivalenz:** Die Variabilität der Fehler innerhalb der Beobachtungen der unabhängigen Variablen sollte näherungsweise gleich sein. Die Fehler sollten gleichmäßig streuen und keine Trends ausbilden.
4. **Normalität:** Die Abweichungen der Messwerte sollten rund um das eingepasste Ergebnismodell normalverteilt sein ("nearly normal condition").

Für jedes dieser Kriterien gibt es diagnostische Plots, die visuell ausgewertet werden müssen. Auf dieser Grundlage kann dann eine Entscheidung über Variablen getroffen werden, die in das Modell aufgenommen werden sollen. Mir stehen allerdings `r ncol(sel3) - 1` potentielle Eingabevariablen zur Verfügung und die Vorabprüfung dieser Variablen hätte viel Zeit in Anspruch genommen. Hinzu kommt, dass das Ergebnis der Multiplen Regression zwar tatsächlich im wesentlichen von den Eingabevariablen abhängig ist, andererseits aber auch -- zumindest wenn sie nicht vollständig unkorreliert sind -- von deren Eingabereihenfolge. Da im Fall der vorliegenden Analyse keine theoretischen oder sachlogischen Überlegungen Eingang finden sollen, die die Variablenauswahl determinieren würden, müssten eigentlich alle Permutationen von Auswahl und Reihenfolge betrachtet werden. Bei `r ncol(sel3) - 1` unabhängigen Variablen ist schon die Anzahl der Permutationen weit größer als praktisch in irgendeiner Form verarbeitbar ($200! \approx 7.887*10^{374}$). 

Ich habe mich entschieden, hier auf eine händische Variablenvorauswahl komplett zu verzichten und stattdessen auf ein automatisches Verfahren der Schrittweisen Regressionsanalyse zurückzugreifen. Diese treffen mittels Prüfgrößen selbständig und in verhältnismäßig wenigen Iterationsschritten eine Variablenauswahl ^[@backhaus_multivariate_2008, 100-105.].  

Die Funktion `stepAIC()` des R Pakets MASS^[@venables_modern_2002, 172-177.] ist eine Implementierung eines solchen Verfahrens. `stepAIC()` erreicht die Modellreduktion durch schrittweise Minimierung der Prüfgröße AIC (Akaike Information Criterion -- $\mathit{AIC} = -2\ *\ \mathit{maximierte}\ \mathit{LogLikelihood}\ +\ 2\ *\ \# Parameter$), die man vereinfacht als Maß für die Passgenauigkeit eines statistischen Modells verstehen kann. `stepAIC()` benötigt dafür ein berechnetes Eingangsmodell, das nach Möglichkeit nah am besten Ergebnismodell liegen sollte, sowie Modelldefinitionen jeweils eines maximal und minimal komplexen Ergebnismodells. Da das Ausgangsmodell mit `r nrow(sel3)` Beobachtungen und `r ncol(sel3)` Variablen in diesem Kontext als komplex gelten darf, möchte ich mich an folgende Empfehlung der Autoren halten, und dem Algorithmus stattdessen nur dieses Initialmodell zur Verfügung stellen.

> If a large model is selected as the starting point, the scope and scale arguments have generally reasonable defaults, but for a small model where the process is probably to be one of adding terms, they will usually need both to be supplied. 
>  
> -- @venables_modern_2002, 175.

Zunächst erfolgt die Berechnung des Ausgangsmodells:

```{r create initial model, echo = TRUE, cache=TRUE} 
initial_model <- lm(larea ~ ., data = sel3)
```

```{r plot initial model, warning=FALSE, cache=TRUE, dependson="create initial model", fig.height=7, fig.cap="\\label{fig:initial_model_plot}Diagnostische Plots für das Ausgangsmodell mit allen Variablen."}
opar <- par(mfrow=c(2,2)) 
plot(initial_model)
par(opar) 
```

Abbildung \ref{fig:initial_model_plot} und Tabelle \ref{tab:initial_model_result_2} zeigen, dass dieses Modell auf Grundlage aller Variablen herausragende Vorhersagefähigkeiten für die Variable *area* besitzt. Gleichermaßen entbehrt es jedoch jeder fachwissenschaftlichen Aussage, da sich eine Gesamtheit von `r ncol(sel3)` semantisch höchst unterschiedlichen Variablen jeder integrativen Interpretation entzieht. Das Modell ist nicht geeignet, ein besseres Verständnis der zugrundeliegenden naturräumlichen, kulturellen und sozioökonomischen Zusammenhänge zu generieren. Erst die Vereinfachung des Modells wird die Ableitung klarer, prüfbarer Hypothesen ermöglichen.

Entsprechend nun also ein erster Durchlauf der automatischen, schrittweisen Modellreduktion: 

```{r stepwise multiple regression, cache=TRUE, dependson="create initial model", message=FALSE, echo=TRUE}
model1 <- MASS::stepAIC(
  initial_model, 
  # trace option: don't show intermediate steps
  trace = FALSE
)
```

```{r plot model1, warning=FALSE, cache=TRUE, dependson="stepwise multiple regression", fig.height=7, fig.cap="\\label{fig:model1_plot}Diagnostische Plots für das Modell nach dem ersten Durchlauf von `stepAIC()`."}
opar <- par(mfrow=c(2,2)) 
plot(model1)
par(opar) 
```

```{r anova table of stepAIC, cache=TRUE, dependson="stepwise multiple regression"}
# nice output table of stepAIC() steps 
model1$anova %>% as.data.frame() %>% dplyr::rename("Dev" = "Deviance") %>% 
  dplyr::select(-Df) %>% 
  knitr::kable(
    format = "latex",
    caption = "\\label{tab:model1_anova}ANOVA Komponente des Ergebnismodelldatentyps von \\texttt{stepAIC()}.  Zeigt die schrittweise Entfernung von Variablen zur Reduktion der Modellkomplexität und zugehörige, diagnostische Prüfgrößen. \\newline \\textbf{Step -- Reduktionsschritt:} Variable, die in diesem Schritt entfernt oder wieder hinzugefügt wurde. \\newline \\textbf{Dev -- Deviance, Resid. Df -- Anzahl der Freiheitsgrade, AIC -- Akaike information criterion:} Siehe Tabelle \\ref{tab:binford_model_result_2}. \\newline \\textbf{Resid. Dev -- residual deviance:} Eine Konstante abzüglich zwei mal die maximierte Log-Likelihood. Ist nur bei gesättigten Modellen aussagekräftig und kann hier ignoriert werden.",
    booktabs = T
  ) %>%
  kableExtra::column_spec(1, bold = TRUE) %>%
  kableExtra::kable_styling(font_size = 9)
```

In Tabelle \ref{tab:model1_anova} werden die Reduktionsschritte zeilenweise dokumentiert. Mit dem Entfernen von Variablen nimmt die Anzahl der Freiheitsgrade schrittweise zu, während der AIC-Wert langsam abnimmt. `r nrow(model1$anova)` Variablen wurden von `stepAIC()` entfernt, dann allerdings kam der Prozess in diesem Durchlauf zum Halten. Der Vergleich des *Residuals vs Leverage* Plots in Abbildung \ref{fig:initial_model_plot} und Abbildung \ref{fig:model1_plot} legt nahe, dass sich die durchschnittliche Wirkung individueller Beobachtungen auf das Gesamtergebnis verringert hat. Anzunehmen ist, dass Variablen mit großer Variabilität entfernt wurden. Abbildung \ref{fig:binford_model_plot} lässt die Vermutung zu, dass sich dieser Trend bei weiterer Reduktion des Modells fortsetzen wird. `r ncol(sel3) - nrow(model1$anova)` Variablen sind tatsächlich angesichts der deskriptiven Einfachheit des Binford-Modells hier noch kein befriedigendes Ergebnis. Die Minimierung des AIC-Werts ist scheinbar kein ausreichend starkes Optimierungskriterium:

> This suggests, correctly, that selecting terms on the basis of AIC can be somewhat permissive in its choice of terms, being roughly equivalent to choosing an F-cutoff of 2.  
>  
> -- @venables_modern_2002, 176.

Wir können nun fortfahren, indem wir entweder das k-Attribut in `stepAIC()` (*the multiple of the number of degrees of freedom used for the penalty*) erhöhen und den Prozess erneut starten, oder direkt mittels F-Statistik schrittweise jene Variablen entfernen, die nicht signifikant mit der abhängigen Variable verknüpft sind. Um diese zu identifizieren steht in MASS die Funktion `dropterm.lm()` bereit, die die Modelleinpassung für alle möglichen Modelle durchführt, die eine Variable weniger inkorporieren als das Ausgangsmodell. 

<!-- https://www.r-bloggers.com/manual-variable-selection-using-the-dropterm-function/ --> 

```{r dropterm example code, eval=FALSE, echo=TRUE}
MASS::dropterm(model1, test = "F")
```

Tabelle \ref{tab:dropterm_example} gibt Einblick in die mit `dropterm(test = "F")` berechneten Prüfgrößen. Offensichtlich verändert sich die Modellgüte je nach dem, welche Variablen ausgeschlossen werden. Die F-Statistik gibt Antwort auf die Frage, ob es gegenüber dem Null-Modell -- also dem Modell, in dem alle Koeffizienten außer dem Y-Achsenabschnitt (Intercept) auf Null gesetzt werden -- einen Vorteil für die Vorhersagequalität des Ergebnismodells bringt, die jeweilige Variable mit in das Modell aufzunehmen. Große Werte für *Pr(F)* deuten also auf Variablen hin, die wahrscheinlich nicht in einer direkten Relation zur abhängigen Variablen stehen und entfernt werden können ^[@venables_modern_2002, 176., @de_veaux_stats:_2012, 792-793.].  

```{r dropterm example table, cache=TRUE, cache=TRUE, dependson="stepwise multiple regression"}
# nice output table of one dropterm() step
MASS::dropterm(model1, test = "F") %>%
  as.data.frame() %>%
  magrittr::extract(1:40, ) %>%
  tibble::rownames_to_column() %>%
  dplyr::select(
    -Df
  ) %>%
  dplyr::mutate_at(
    c("Sum of Sq", "RSS", "F Value"),
    dplyr::funs(round(., 4))
  ) %>% 
  dplyr::mutate_at(
    c("AIC"),
    dplyr::funs(round(., 0))
  ) %>%
  dplyr::mutate_at(
    c("Pr(F)"),
    dplyr::funs(round(., 4))
  ) %>%
  dplyr::mutate_all(
    dplyr::funs(as.character(.))
  ) %>%
  # add decorative ... at the end
  rbind(
    ., 
    data.frame(
      rowname = "...", `Sum of Sq` = "...", RSS = "...", AIC = "...",
      `F Value` = "...", `Pr(F)` = "...", check.names = F
    )
  ) %>%
  knitr::kable(
    format = "latex",
    caption = "\\label{tab:dropterm_example}dropterm Tabelle: Maße für die Qualität des Beitrags einzelner Variablen zum Gesamtmodell. Alle Werte sind auf vier Nachkommastellen gerundet, der AIC-Wert auf ganze Zahlen. \\newline \\textbf{Sum of Sq -- ESS -- explained sum of squares:} Summe der Abweichungsquadrate der Modellvorhersage zum arithmetischen Mittel der abhängigen Variable für das Modell ohne diese Variable. \\newline \\textbf{RSS -- residual sum of squares:} Wie ESS, hier aber Summe der Abweichungsquadrate der Modellvorhersage zu \\textit{allen} Werten der abhängigen Variable. \\newline \\textbf{AIC -- Akaike information criterion:} Siehe Tabelle \\ref{tab:binford_model_result_2}. \\newline \\textbf{F Value:} Eingangswert des F-Tests. \\newline \\textbf{Pr(F) -- probability of F-Value:} Maß für die Wahrscheinlichkeit (p-Wert) des F-Werts im F-Test der Gesamtsignifikanz. Der F-Test basiert auf dem Vergleich mit einem Modell, in dem alle Koeffizienten außer dem Intercept und dem der aktuellen Variable den Wert Null annehmen. Ist die Wahrscheinlichkeit klein, kann die Nullhypothese, dass kein wirklicher Zusammenhang zwischen abhängiger und unabhängigen Variablen besteht, verworfen werden.",
    booktabs = T
  ) %>%
  kableExtra::column_spec(1, bold = TRUE)
```

```{r initial model estimate table 2, cache=TRUE, dependson="create initial model"}
init_mod_vals <- initial_model %>%
  broom::glance() %>%
  tidyr::gather(var, value) %>% 
  dplyr::mutate(
    var2 = c(var[7:11], rep(NA, 6)),
    value2 = c(value[7:11], rep(NA, 6))
  ) %>%
  magrittr::extract(1:5,) %>%
  dplyr::mutate_if(
    is.numeric,
    dplyr::funs(round(., 3))
  ) %>% dplyr::mutate_if(
    is.numeric,
    as.character
  ) %>%
  dplyr::rename(
    " " = "var",
    " " = "var2",
    "value" = "value2"
  )

init_mod_vals[is.na(init_mod_vals)] <- ""

init_mod_vals %>%
  knitr::kable(
    format = "latex",
    caption = "\\label{tab:initial_model_result_2}Ergebniszusammenfassung des initialen Modells. Alle Werte sind auf drei Nachkommastellen gerundet.",
    booktabs = T
  ) %>%
  kableExtra::column_spec(1, bold = TRUE) %>%
  kableExtra::column_spec(3, bold = TRUE)
```

Ich möchte das Vorgehen, mit `dropterm()` schrittweise Variablen zu entfernen, automatisieren und dann so oft wiederholt zur Anwendung bringen, bis die Anzahl der Variablen im Ergebnismodell der in Binfords Modell entspricht. Dafür habe ich einen simplen Algorithmus formuliert, der in einer Schleife die `dropterm()`-Funktion ausführt, die Variable mit dem größten p-Wert identifiziert und diese dann dann für den nächsten Schleifendurchlauf aus dem immer einfacheren Modell entfernt. 

```{r dropterm loop, echo=TRUE, cache=TRUE, dependson="stepwise multiple regression"}
# dublicate model object 
model2 <- model1

# determine number of vars to drop
to_drop <- (ncol(sel3) - nrow(model1$anova) - 10)

# drop loop
for (i in 1:to_drop) {
  # determine variable with highest 
  # p-value of the F-Test
  victimvar <- MASS::dropterm(
      model2, test = "F"
    ) %>% 
    tibble::as.tibble() %>%
    tibble::rownames_to_column() %>%
    dplyr::top_n(
     1, `Pr(F)`
    ) 
  
  # remove this variable from the model
  model2 <- update(
    model2, 
    as.formula(paste(
      ". ~ . - ", victimvar$rowname
    ))
  ) 
}
```

```{r plot model2, warning=FALSE, cache=TRUE, dependson="dropterm loop", fig.height=7, fig.cap="\\label{fig:model2_plot}Diagnostische Plots für das Modell nach Anwendung des `dropterm()`-Algorithmus."}
opar <- par(mfrow=c(2,2)) 
plot(model2)
par(opar) 
```

```{r, cache=TRUE, dependson="dropterm loop"}
model2 %>%
  broom::tidy() %>%
  dplyr::mutate_if(
    is.numeric,
    dplyr::funs(round(., 3))
  ) %>%
  knitr::kable(
    format = "latex",
    caption = "\\label{tab:model2_result}Ergebniszusammenfassung für die einzelnen Koeffizienten des mittels \\texttt{stepAIC()} und \\texttt{dropterm()} aus der Gesamtvariablenmenge reduzierten Modells. Alle Werte sind auf drei Nachkommastellen gerundet.",
    booktabs = T
  ) %>%
  kableExtra::column_spec(1, bold = TRUE)
```

```{r bad variables, cache=TRUE}
# get variable descriptions
# hu <- key %>%
#   dplyr::filter(
#     variable %in% colnames(sel3)
#   ) %>%
#   dplyr::select(
#     variable, description
#   )

# manually identify variables, that are directly linked to area
bad_vars <- c("density", "packinx", "prindx", "lden", "lpackinx")
```

Das Modell, das aus diesem Algorithmus hervorgeht, erscheint im ersten Moment äußert vielversprechend. Abbildung \ref{fig:model2_plot} zeigt, dass es äußerst präzise Vorhersagen für *larea* erlaubt und -- abgesehen von wenigen, starken Ausreißern -- die Mehrzahl der Beobachtungen hervorragend erklärt. Ein Blick in Tabelle \ref{tab:model2_result} offenbart jedoch, dass das Modell im wesentlichen auf den beiden Variablen *lnpop* und *lpackinx* beruht. Obgleich die Koeffizientenwerte bei der Multiplen Regression nicht so unmittelbar verstanden werden können, wie das bei der Einfachen Regression möglich ist ^[@de_veaux_stats:_2012, 787-788 & 794.], ist doch klar, dass die anderen Variablen verschwindend wenig Einfluss auf das Ergebnis haben. *packinx* ist eine umskalierte Variante der Bevölkerungsdichte ^[@binford_constructing_2001, 117.], die sich selbst als abhängige Größe aus Bevölkerungszahl und Arealgröße definiert. Es ist also nicht verwunderlich, dass sich die logarithmisch skalierte Variante *lpackinx* gut zur Vorhersage von *larea* eignet. Um ein Ergebnis zu erhalten, dass mehr wissenschaftliche Relevanz besitzt, muss ich jene Variablen aus dem Ausgangsdatensatz entfernen, die direkt von der Arealgröße abhängig sind. Eine kurze Durchsicht der Schlüsseldatei LRBkey reduziert auf die oben getroffene Selektion metrisch skalierter Variablen ergibt dazu folgende Auswahl: `r paste(paste0("*", bad_vars, "*"), collapse = ", ")`. Freilich könnte man argumentieren, dass auch die Beziehung zwischen *larea* und der logarithmisch skalierten Bevölkerungszahl *lnpop*, die in Tabelle \ref{tab:model2_result} ebenfalls deutlich als relevante Vorhersagegröße angeführt wird, trivial ist und entsprechend ausgeschlossen werden könnte. Das führt allerdings zu einer fortgeschrittenen, manuellen Variablenvorauswahl. Eine solche kann fragestellungsbezogen durchaus sinnvoll sein, wurde hier aber bewusst vermieden. Die Abwesenheit von *lpackinx* und *lnpop* in Binfords Ergebnismodell (siehe \ref{eq:area_multi_log}) spricht dafür, dass Binford hier Hand angelegt hat, ohne das explizit zu kommunizieren. Möglicherweise waren diese Variablen aber auch überhaupt nicht Teil der Arbeitsversion des Gruppendatensatzes, die ihm zum Zeitpunkt der Erstellung dieses Modells zur Verfügung stand.  

Hier nun also ein Blick auf das Modell, das sich ergibt, wenn man die beschriebene Variablenvorauswahl trifft und noch einmal die Arbeitsschritte des `stepAIC()`- und `dropterm()`-Algorithmus wiederholt.

```{r final model, cache=TRUE, dependson="bad variables"}
# remove those variables
sel5 <- sel3 %>%
  dplyr::select(
    -dplyr::one_of(bad_vars)
  )

# create initial model with new variable selection
initial_model2 <- lm(larea ~ ., data = sel5)

# reduce model with stepAIC()
model3 <- MASS::stepAIC(
  initial_model2, 
  trace = FALSE
)

# dublicate model object 
model4 <- model3

# determine number of vars to drop
to_drop <- (ncol(sel5) - nrow(model3$anova) - 10)

# drop loop
for (i in 1:to_drop) {
  # determine variable with highest 
  # p-value of the F-Test
  victimvar <- MASS::dropterm(
      model4, test = "F"
    ) %>% 
    tibble::as.tibble() %>%
    tibble::rownames_to_column() %>%
    dplyr::top_n(
     1, `Pr(F)`
    ) 
  
  # remove this variable from the model
  model4 <- update(
    model4, 
    as.formula(paste(
      ". ~ . - ", victimvar$rowname
    ))
  ) 
}
```

```{r plot model4, warning=FALSE, cache=TRUE, dependson="dropterm loop", fig.height=7, fig.cap="\\label{fig:model4_plot}Diagnostische Plots für das finale Modell."}
opar <- par(mfrow=c(2,2)) 
plot(model4)
par(opar) 
```

```{r final model estimate table, cache=TRUE, dependson="dropterm loop"}
model4 %>%
  broom::tidy() %>%
  dplyr::mutate_if(
    is.numeric,
    dplyr::funs(round(., 3))
  ) %>%
  knitr::kable(
    format = "latex",
    caption = "\\label{tab:model4_result}Ergebniszusammenfassung für die einzelnen Koeffizienten des finalen Modells, das durch erneute Anwendung des \\texttt{stepAIC()}- und \\texttt{dropterm()}-Algorithmus auf ein Modell mit leicht reduzierter Variablenauswahl ermittelt wurde. Alle Werte sind auf drei Nachkommastellen gerundet.",
    booktabs = T
  ) %>%
  kableExtra::column_spec(1, bold = TRUE)
```

```{r final model estimate table 2, cache=TRUE, dependson="dropterm loop"}
fin_mod_vals <- model4 %>%
  broom::glance() %>%
  tidyr::gather(var, value) %>% 
  dplyr::mutate(
    var2 = c(var[7:11], rep(NA, 6)),
    value2 = c(value[7:11], rep(NA, 6))
  ) %>%
  magrittr::extract(1:5,) %>%
  dplyr::mutate_if(
    is.numeric,
    dplyr::funs(round(., 3))
  ) %>% dplyr::mutate_if(
    is.numeric,
    as.character
  ) %>%
  dplyr::rename(
    " " = "var",
    " " = "var2",
    "value" = "value2"
  )

fin_mod_vals[is.na(fin_mod_vals)] <- ""

fin_mod_vals %>%
  knitr::kable(
    format = "latex",
    caption = "\\label{tab:model4_result_2}Ergebniszusammenfassung des finalen Modells. Alle Werte sind auf drei Nachkommastellen gerundet.",
    booktabs = T
  ) %>%
  kableExtra::column_spec(1, bold = TRUE) %>%
  kableExtra::column_spec(3, bold = TRUE)
```

\begin{equation} \label{eq:area_final}
\begin{aligned}
\log _{10} \mathit{area} = \\
\mathit{larea} = \\
    & 2.439 + \\ 
    & (-0.021 * \mathit{temp}) + \\
    & (-0.132 * \mathit{medstab}) + \\
    & (0.259 * \mathit{perwret}) + \\
    & (-0.498 * \mathit{perwltg}) + \\
    & (-0.760 * \mathit{lnagp}) + \\
    & (0.372 * \mathit{lnpop}) + \\
    & (0.005 * \mathit{gatherin}) + \\
    & (0.001 * \mathit{kmov}) + \\
    & (-0.002 * \mathit{nicheff}) + \\
    & (-0.006 * \mathit{lati})
\end{aligned}
\end{equation}

Aus Tabelle \ref{tab:model4_result} (und Gleichung \ref{eq:area_final}) wird ersichtlich, dass dieses Modell nun auf einer wesentlich diverseren Auswahl unabhängiger Variablen fußt. Abbildung \ref{fig:model4_plot} und Tabelle \ref{tab:model4_result_2} belegen, dass es sich um ein solides Modell handelt. Den Kennwerten in Tabelle \ref{tab:binford_model_result_2} nach zu urteilen, scheint es wesentlich bessere Vorhersagen treffen zu können als Binfords Modell: Während das Modell, das ich auf Grundlage von Binfords Variablenauswahl ermittelt habe nur ($R^2 \approx$) `r round(summary(binford_model)$r.squared * 100, 1)`% der Variabilität in *larea* erklären konnte, kommt dieses Modell auf `r round(summary(model4)$r.squared * 100, 1)`%! Dieses Ergebnis ist eindeutig -- selbst wenn man die Unzulänglichkeiten von $R^2$ und $\mathit{adjusted} R^2$ für den Modellvergleich in Betracht zieht ^[@de_veaux_stats:_2012, 799-800.]. Ich möchte damit also den Reproduktionsversuch abschließen und die Ergebnisse diskutieren.

```{r child = 'binford_discussion.Rmd'}
```
